---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
  name: kubecf-default
spec:
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - NET_BIND_SERVICE
  - SYS_ADMIN
  - SYS_RESOURCE
  defaultAllowPrivilegeEscalation: true
  fsGroup:
    rule: RunAsAny
  hostPorts:
  - max: 65535
    min: 0
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - configMap
  - secret
  - emptyDir
  - downwardAPI
  - projected
  - persistentVolumeClaim
  - nfs
  - rbd
  - cephFS
  - glusterfs
  - fc
  - iscsi
  - cinder
  - gcePersistentDisk
  - awsElasticBlockStore
  - azureDisk
  - azureFile
  - vsphereVolume
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: var-system-domain
  namespace: default
stringData:
  value: kubecf.vcap.me
type: Opaque
---
apiVersion: v1
data:
  manifest: |-
    ---
    name: cf
    manifest_version: v13.9.0
    update:
      canaries: 1
      canary_watch_time: 30000-1200000
      max_in_flight: 1
      serial: false
      update_watch_time: 5000-1200000
    addons:
    - name: loggregator_agent
      include:
        stemcell:
        - os: ubuntu-xenial
      exclude:
        jobs:
        - name: smoke_tests
          release: cf-smoke-tests
      jobs:
      - name: loggregator_agent
        release: loggregator-agent
        properties:
          grpc_port: 3459
          disable_udp: true
          loggregator:
            tls:
              ca_cert: "((loggregator_tls_agent.ca))"
              agent:
                cert: "((loggregator_tls_agent.certificate))"
                key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggregator_agent_metrics_tls.ca))"
            cert: "((loggregator_agent_metrics_tls.certificate))"
            key: "((loggregator_agent_metrics_tls.private_key))"
            server_name: loggregator_agent_metrics

    - name: forwarder_agent
      include:
        stemcell:
        - os: ubuntu-xenial
      jobs:
      - name: loggr-forwarder-agent
        release: loggregator-agent
        properties:
          tls:
            ca_cert: "((loggregator_tls_agent.ca))"
            cert: "((loggregator_tls_agent.certificate))"
            key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((forwarder_agent_metrics_tls.ca))"
            cert: "((forwarder_agent_metrics_tls.certificate))"
            key: "((forwarder_agent_metrics_tls.private_key))"
            server_name: forwarder_agent_metrics

    - name: loggr-syslog-agent
      include:
        stemcell:
        - os: ubuntu-trusty
        - os: ubuntu-xenial
      exclude:
        jobs:
        - name: smoke_tests
          release: cf-smoke-tests
      jobs:
      - name: loggr-syslog-agent
        release: loggregator-agent
        properties:
          port: 3460
          tls:
            ca_cert: "((loggregator_tls_agent.ca))"
            cert: "((loggregator_tls_agent.certificate))"
            key: "((loggregator_tls_agent.private_key))"
          cache:
            tls:
              ca_cert: "((syslog_agent_api_tls.ca))"
              cert: "((syslog_agent_api_tls.certificate))"
              key: "((syslog_agent_api_tls.private_key))"
              cn: "binding-cache"
          metrics:
            ca_cert: "((syslog_agent_metrics_tls.ca))"
            cert: "((syslog_agent_metrics_tls.certificate))"
            key: "((syslog_agent_metrics_tls.private_key))"
            server_name: syslog_agent_metrics

    - name: prom_scraper
      include:
        stemcell:
          - os: ubuntu-xenial
      exclude:
        jobs:
        - name: smoke_tests
          release: cf-smoke-tests
      jobs:
      - name: prom_scraper
        release: loggregator-agent
        properties:
          scrape:
            tls:
              ca_cert: "((prom_scraper_scrape_tls.ca))"
              cert: "((prom_scraper_scrape_tls.certificate))"
              key: "((prom_scraper_scrape_tls.private_key))"
          metrics:
            ca_cert: "((prom_scraper_metrics_tls.ca))"
            cert: "((prom_scraper_metrics_tls.certificate))"
            key: "((prom_scraper_metrics_tls.private_key))"
            server_name: prom_scraper_metrics

    - name: metrics-discovery-registrar
      exclude:
        jobs:
        - name: smoke_tests
          release: cf-smoke-tests
      include:
        stemcell:
        - os: ubuntu-trusty
        - os: ubuntu-xenial
      jobs:
      - name: metrics-discovery-registrar
        properties:
          metrics:
            ca_cert: ((metrics_discovery_metrics_tls.ca))
            cert: ((metrics_discovery_metrics_tls.certificate))
            key: ((metrics_discovery_metrics_tls.private_key))
            server_name: metrics_discovery_metrics
          nats_client:
            cert: ((nats_client_cert.certificate))
            key: ((nats_client_cert.private_key))
        release: metrics-discovery

    - name: metrics-agent
      exclude:
        jobs:
        - name: smoke_tests
          release: cf-smoke-tests
      include:
        stemcell:
        - os: ubuntu-xenial
      jobs:
      - name: metrics-agent
        properties:
          grpc:
            ca_cert: ((loggregator_tls_agent.ca))
            cert: ((loggregator_tls_agent.certificate))
            key: ((loggregator_tls_agent.private_key))
          metrics:
            ca_cert: ((metrics_agent_tls.ca))
            cert: ((metrics_agent_tls.certificate))
            key: ((metrics_agent_tls.private_key))
            server_name: metrics_agent
          scrape:
            tls:
              ca_cert: ((prom_scraper_scrape_tls.ca))
              cert: ((prom_scraper_scrape_tls.certificate))
              key: ((prom_scraper_scrape_tls.private_key))
        release: metrics-discovery

    - name: bpm
      include:
        stemcell:
        - os: ubuntu-xenial
      jobs:
      - name: bpm
        release: bpm
    - name: bosh-dns-aliases
      jobs:
      - name: bosh-dns-aliases
        release: bosh-dns-aliases
        properties:
          aliases:
          - domain: '_.cell.service.cf.internal'
            targets:
            - query: '_'
              instance_group: diego-cell
              deployment: cf
              network: default
              domain: bosh
            - query: '_'
              instance_group: windows2019-cell
              deployment: cf
              network: default
              domain: bosh
            - query: '_'
              instance_group: isolated-diego-cell
              deployment: cf
              network: default
              domain: bosh
          - domain: auctioneer.service.cf.internal
            targets:
            - query: 'q-s4'
              instance_group: scheduler
              deployment: cf
              network: default
              domain: bosh
          - domain: bbs.service.cf.internal
            targets:
            - query: 'q-s4'
              instance_group: diego-api
              deployment: cf
              network: default
              domain: bosh
          - domain: blobstore.service.cf.internal
            targets:
            - query: '*'
              instance_group: singleton-blobstore
              deployment: cf
              network: default
              domain: bosh
          - domain: cc-uploader.service.cf.internal
            targets:
            - query: '*'
              instance_group: api
              deployment: cf
              network: default
              domain: bosh
          - domain: cloud-controller-ng.service.cf.internal
            targets:
            - query: '*'
              instance_group: api
              deployment: cf
              network: default
              domain: bosh
          - domain: credhub.service.cf.internal
            targets:
            - query: '*'
              instance_group: credhub
              deployment: cf
              network: default
              domain: bosh
          - domain: doppler.service.cf.internal
            targets:
            - query: '*'
              instance_group: doppler
              deployment: cf
              network: default
              domain: bosh
          - domain: file-server.service.cf.internal
            targets:
            - query: '*'
              instance_group: api
              deployment: cf
              network: default
              domain: bosh
          - domain: gorouter.service.cf.internal
            targets:
            - query: '*'
              instance_group: router
              deployment: cf
              network: default
              domain: bosh
          - domain: locket.service.cf.internal
            targets:
            - query: '*'
              instance_group: diego-api
              deployment: cf
              network: default
              domain: bosh
          - domain: loggregator-trafficcontroller.service.cf.internal
            targets:
            - query: '*'
              instance_group: log-api
              deployment: cf
              network: default
              domain: bosh
          - domain: policy-server.service.cf.internal
            targets:
            - query: '*'
              instance_group: api
              deployment: cf
              network: default
              domain: bosh
          - domain: reverse-log-proxy.service.cf.internal
            targets:
            - query: '*'
              instance_group: log-api
              deployment: cf
              network: default
              domain: bosh
          - domain: routing-api.service.cf.internal
            targets:
            - query: '*'
              instance_group: api
              deployment: cf
              network: default
              domain: bosh
          - domain: silk-controller.service.cf.internal
            targets:
            - query: '*'
              instance_group: diego-api
              deployment: cf
              network: default
              domain: bosh
          - domain: sql-db.service.cf.internal
            targets:
            - query: '*'
              instance_group: database
              deployment: cf
              network: default
              domain: bosh
          - domain: ssh-proxy.service.cf.internal
            targets:
            - query: '*'
              instance_group: scheduler
              deployment: cf
              network: default
              domain: bosh
          - domain: tps.service.cf.internal
            targets:
            - query: '*'
              instance_group: scheduler
              deployment: cf
              network: default
              domain: bosh
          - domain: uaa.service.cf.internal
            targets:
            - query: '*'
              instance_group: uaa
              deployment: cf
              network: default
              domain: bosh
          - domain: nats.service.cf.internal
            targets:
            - query: '*'
              instance_group: nats
              deployment: cf
              network: default
              domain: bosh
          - domain: _.nats.service.cf.internal
            targets:
            - query: '_'
              instance_group: nats
              deployment: cf
              network: default
              domain: bosh


    instance_groups:
    - name: smoke-tests
      lifecycle: errand
      azs:
      - z1
      instances: 1
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: smoke_tests
        release: cf-smoke-tests
        properties:
          bpm:
            enabled: true
          smoke_tests:
            api: "https://api.((system_domain))"
            apps_domain: "((system_domain))"
            client: cf_smoke_tests
            client_secret: "((uaa_clients_cf_smoke_tests_secret))"
            org: cf_smoke_tests_org
            space: cf_smoke_tests_space
            cf_dial_timeout_in_seconds: 300
            skip_ssl_validation: true
      - name: cf-cli-6-linux
        release: cf-cli
    - name: nats
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: nats
        release: nats
        provides:
          nats: {as: nats, shared: true}
        properties:
          nats:
            hostname: nats.service.cf.internal
            user: nats
            password: "((nats_password))"
            internal:
              tls:
                ca: "((nats_internal_cert.ca))"
                certificate: "((nats_internal_cert.certificate))"
                enabled: true
                private_key: "((nats_internal_cert.private_key))"
      - name: nats-tls
        release: nats
        provides:
          nats-tls: {as: nats-tls, shared: true}
        custom_provider_definitions:
        - name: nats-tls-address
          type: address
        properties:
          nats:
            hostname: nats.service.cf.internal
            user: nats
            password: "((nats_password))"
            internal:
              tls:
                ca: "((nats_internal_cert.ca))"
                private_key: "((nats_internal_cert.private_key))"
                certificate: "((nats_internal_cert.certificate))"
                enabled: true
            external:
              tls:
                ca: "((nats_client_cert.ca))"
                private_key: "((nats_server_cert.private_key))"
                certificate: "((nats_server_cert.certificate))"
    - name: database
      migrated_from:
      - name: mysql
      - name: singleton-database
      azs:
      - z1
      persistent_disk_type: 10GB
      instances: 1
      vm_type: small
      stemcell: default
      update:
        serial: true
      networks:
      - name: default
      jobs:
      - name: pxc-mysql
        release: pxc
        properties:
          admin_password: ((cf_mysql_mysql_admin_password))
          engine_config:
            binlog:
              enabled: false
            galera:
              enabled: true
          port: 13306
          seeded_databases:
          - name: cloud_controller
            password: ((cc_database_password))
            username: cloud_controller
          - name: diego
            password: ((diego_database_password))
            username: diego
          - name: network_connectivity
            password: ((network_connectivity_database_password))
            username: network_connectivity
          - name: network_policy
            password: ((network_policy_database_password))
            username: network_policy
          - name: routing-api
            password: ((routing_api_database_password))
            username: routing-api
          - name: uaa
            password: ((uaa_database_password))
            username: uaa
          - name: locket
            password: ((locket_database_password))
            username: locket
          - name: credhub
            password: ((credhub_database_password))
            username: credhub
          tls:
            galera: ((galera_server_certificate))
            server: ((mysql_server_certificate))
      - name: proxy
        release: pxc
        properties:
          api_password: ((cf_mysql_proxy_api_password))
          api_port: 8083
          api_uri: proxy.((system_domain))
      - name: galera-agent
        release: pxc
        properties:
          db_password: ((cf_mysql_mysql_galera_healthcheck_password))
          endpoint_password: ((cf_mysql_mysql_galera_healthcheck_endpoint_password))
      - name: gra-log-purger
        release: pxc
      - name: cluster-health-logger
        release: pxc
        properties:
          db_password: ((cf_mysql_mysql_cluster_health_password))
      - name: route_registrar
        release: routing
        properties:
          route_registrar:
            routes:
            - name: cf-mysql-proxy
              port: 8083
              prepend_instance_index: true
              registration_interval: 10s
              uris:
              - proxy.((system_domain))
            - name: cf-mysql-proxy-aggregator
              port: 8082
              registration_interval: 10s
              uris:
              - proxy.((system_domain))
      - name: bootstrap
        release: pxc
    - name: diego-api
      migrated_from:
      - name: diego-bbs
      azs:
      - z1
      - z2
      instances: 2
      vm_type: small
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: cfdot
        release: diego
        properties:
          tls: &cfdot_tls_client_properties
            ca_certificate: "((diego_rep_client.ca))"
            certificate: "((diego_rep_client.certificate))"
            private_key: "((diego_rep_client.private_key))"
      - name: bbs
        release: diego
        properties:
          bpm:
            enabled: true
          diego:
            bbs:
              active_key_label: key-2016-06
              detect_consul_cell_registrations: false
              encryption_keys:
              - label: key-2016-06
                passphrase: "((diego_bbs_encryption_keys_passphrase))"
              sql:
                db_host: sql-db.service.cf.internal
                db_port: 3306
                db_schema: diego
                db_username: diego
                db_password: "((diego_database_password))"
                db_driver: mysql
                ca_cert: "((mysql_server_certificate.ca))"
                require_ssl: true
              ca_cert: "((diego_bbs_server.ca))"
              auctioneer: &diego_auctioneer_client_properties
                ca_cert: "((diego_auctioneer_client.ca))"
                client_cert: "((diego_auctioneer_client.certificate))"
                client_key: "((diego_auctioneer_client.private_key))"
              server_cert: "((diego_bbs_server.certificate))"
              server_key: "((diego_bbs_server.private_key))"
              skip_consul_lock: true
              rep:
                require_tls: true
                ca_cert: "((diego_rep_client.ca))"
                client_cert: "((diego_rep_client.certificate))"
                client_key: "((diego_rep_client.private_key))"
          enable_consul_service_registration: false
          loggregator: &diego_loggregator_client_properties
            use_v2_api: true
            ca_cert: "((loggregator_tls_agent.ca))"
            cert: "((loggregator_tls_agent.certificate))"
            key: "((loggregator_tls_agent.private_key))"
          logging:
            format:
              timestamp: "rfc3339"
      - name: silk-controller
        release: silk
        properties:
          ca_cert: ((silk_controller.ca))
          server_cert: ((silk_controller.certificate))
          server_key: ((silk_controller.private_key))
          database:
            type: mysql
            username: network_connectivity
            password: ((network_connectivity_database_password))
            host: sql-db.service.cf.internal
            port: 3306
            name: network_connectivity
            ca_cert: "((mysql_server_certificate.ca))"
            require_ssl: true
          silk_daemon:
            ca_cert: ((silk_daemon.ca))
            client_cert: ((silk_daemon.certificate))
            client_key: ((silk_daemon.private_key))
      - name: locket
        release: diego
        properties:
          bpm:
            enabled: true
          tls:
            ca_cert: "((diego_locket_server.ca))"
            cert: "((diego_locket_server.certificate))"
            key: "((diego_locket_server.private_key))"
          diego:
            locket:
              sql:
                db_host: sql-db.service.cf.internal
                db_port: 3306
                db_schema: locket
                db_username: locket
                db_password: "((locket_database_password))"
                db_driver: mysql
                ca_cert: "((mysql_server_certificate.ca))"
                require_ssl: true
          enable_consul_service_registration: false
          loggregator:
            use_v2_api: true
            ca_cert: "((loggregator_tls_agent.ca))"
            cert: "((loggregator_tls_agent.certificate))"
            key: "((loggregator_tls_agent.private_key))"
          logging:
            format:
              timestamp: "rfc3339"
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics

    - name: uaa
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: uaa
        release: uaa
        properties:
          encryption:
            active_key_label: default_key
            encryption_keys:
            - label: default_key
              passphrase: ((uaa_default_encryption_passphrase))
          login:
            saml:
              activeKeyId: key-1
              keys:
                key-1:
                  key: "((uaa_login_saml.private_key))"
                  certificate: "((uaa_login_saml.certificate))"
                  passphrase: ""
          uaa:
            sslCertificate: "((uaa_ssl.certificate))"
            sslPrivateKey: "((uaa_ssl.private_key))"
            zones:
              internal:
                hostnames:
                - uaa.service.cf.internal
            url: https://uaa.((system_domain))
            admin:
              client_secret: "((uaa_admin_client_secret))"
            logging_level: INFO
            scim:
              users:
              - name: admin
                password: "((cf_admin_password))"
                groups:
                - clients.read
                - cloud_controller.admin
                - doppler.firehose
                - network.admin
                - openid
                - routing.router_groups.read
                - routing.router_groups.write
                - scim.read
                - scim.write
            jwt:
              policy:
                active_key_id: key-1
                keys:
                  key-1:
                    signingKey: "((uaa_jwt_signing_key.private_key))"
            clients:
              cc_routing:
                authorities: routing.router_groups.read
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_cc-routing_secret))"
              cc-service-dashboards:
                authorities: clients.read,clients.write,clients.admin
                authorized-grant-types: client_credentials
                scope: openid,cloud_controller_service_permissions.read
                secret: "((uaa_clients_cc-service-dashboards_secret))"
              cc_service_key_client:
                authorities: credhub.read,credhub.write
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_cc_service_key_client_secret))"
              cf:
                access-token-validity: 600
                authorities: uaa.none
                authorized-grant-types: password,refresh_token
                override: true
                refresh-token-validity: 2592000
                scope: network.admin,network.write,cloud_controller.read,cloud_controller.write,openid,password.write,cloud_controller.admin,scim.read,scim.write,doppler.firehose,uaa.user,routing.router_groups.read,routing.router_groups.write,cloud_controller.admin_read_only,cloud_controller.global_auditor,perm.admin,clients.read
                secret: ''
              cf_smoke_tests:
                authorities: cloud_controller.admin
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_cf_smoke_tests_secret))"
              cloud_controller_username_lookup:
                authorities: scim.userids
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_cloud_controller_username_lookup_secret))"
              credhub_admin_client:
                authorities: credhub.read,credhub.write
                authorized-grant-types: client_credentials
                secret: ((credhub_admin_client_secret))
              doppler:
                authorities: uaa.resource
                override: true
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_doppler_secret))"
              gorouter:
                authorities: routing.routes.read
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_gorouter_secret))"
              ssh-proxy:
                authorized-grant-types: authorization_code
                autoapprove: true
                override: true
                redirect-uri: "https://uaa.((system_domain))/login"
                scope: openid,cloud_controller.read,cloud_controller.write,cloud_controller.admin
                secret: "((uaa_clients_ssh-proxy_secret))"
              routing_api_client:
                authorities: routing.routes.write,routing.routes.read,routing.router_groups.read
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_routing_api_client_secret))"
              network-policy:
                authorities: uaa.resource,cloud_controller.admin_read_only
                authorized-grant-types: client_credentials
                secret: ((uaa_clients_network_policy_secret))
              tcp_emitter:
                authorities: routing.routes.write,routing.routes.read
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_tcp_emitter_secret))"
              tcp_router:
                authorities: routing.routes.read
                authorized-grant-types: client_credentials
                secret: "((uaa_clients_tcp_router_secret))"
            ca_certs:
            - "((mysql_server_certificate.ca))"
          uaadb:
            address: sql-db.service.cf.internal
            databases:
            - name: uaa
              tag: uaa
            db_scheme: mysql
            port: 3306
            roles:
            - name: uaa
              password: "((uaa_database_password))"
              tag: admin
      - name: route_registrar
        release: routing
        properties:
          route_registrar:
            routes:
            - health_check:
                name: uaa-healthcheck
                script_path: "/var/vcap/jobs/uaa/bin/dns/healthy"
              name: uaa
              tls_port: 8443
              server_cert_domain_san: "uaa.service.cf.internal"
              registration_interval: 10s
              tags:
                component: uaa
              uris:
              - uaa.((system_domain))
              - "*.uaa.((system_domain))"
              - login.((system_domain))
              - "*.login.((system_domain))"
      - name: statsd_injector
        release: statsd-injector
        properties: &statsd_injector_properties
          loggregator:
            tls:
              ca_cert: "((loggregator_tls_statsdinjector.ca))"
              statsd_injector:
                cert: "((loggregator_tls_statsdinjector.certificate))"
                key: "((loggregator_tls_statsdinjector.private_key))"
    - name: singleton-blobstore
      migrated_from:
      - name: blobstore
      azs:
      - z1
      instances: 1
      vm_type: small
      persistent_disk_type: 100GB
      stemcell: default
      update:
        serial: true
      networks:
      - name: default
      jobs:
      - name: blobstore
        release: capi
        properties:
          select_directories_to_backup:
          - "buildpacks"
          - "packages"
          - "droplets"
          system_domain: "((system_domain))"
          blobstore:
            admin_users:
            - username: blobstore-user
              password: "((blobstore_admin_users_password))"
            secure_link:
              secret: "((blobstore_secure_link_secret))"
            tls:
              cert: "((blobstore_tls.certificate))"
              private_key: "((blobstore_tls.private_key))"
      - name: route_registrar
        release: routing
        properties:
          route_registrar:
            routes:
            - name: blobstore
              port: 8080
              registration_interval: 20s
              tags:
                component: blobstore
              uris:
              - blobstore.((system_domain))
    - name: api
      azs:
      - z1
      - z2
      instances: 2
      vm_type: small
      vm_extensions:
      - 50GB_ephemeral_disk
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: cloud_controller_ng
        release: capi
        provides:
          cloud_controller: {as: cloud_controller, shared: true}
        properties:
          router:
            route_services_secret: "((router_route_services_secret))"
          system_domain: "((system_domain))"
          app_domains:
          - "((system_domain))"
          - name: apps.internal
            internal: true
          app_ssh:
            host_key_fingerprint: "((diego_ssh_proxy_host_key.public_key_fingerprint))"
          routing_api: &routing_api
            enabled: true
          credhub_api:
            ca_cert: ((credhub_tls.ca))
          ssl:
            skip_cert_verify: true
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            clients:
              cc_routing:
                secret: "((uaa_clients_cc-routing_secret))"
              cloud_controller_username_lookup:
                secret: "((uaa_clients_cloud_controller_username_lookup_secret))"
              cc-service-dashboards:
                secret: "((uaa_clients_cc-service-dashboards_secret))"
              cc_service_key_client:
                secret: "((uaa_clients_cc_service_key_client_secret))"
            url: https://uaa.((system_domain))
          cc:
            diego:
              docker_staging_stack: cflinuxfs3
            stacks:
            - name: cflinuxfs3
              description: Cloud Foundry Linux-based filesystem (Ubuntu 18.04)
            default_running_security_groups:
            - public_networks
            - dns
            default_staging_security_groups:
            - public_networks
            - dns
            security_group_definitions:
            - name: public_networks
              rules:
              - destination: 0.0.0.0-9.255.255.255
                protocol: all
              - destination: 11.0.0.0-169.253.255.255
                protocol: all
              - destination: 169.255.0.0-172.15.255.255
                protocol: all
              - destination: 172.32.0.0-192.167.255.255
                protocol: all
              - destination: 192.169.0.0-255.255.255.255
                protocol: all
            - name: dns
              rules:
              - destination: 0.0.0.0/0
                ports: '53'
                protocol: tcp
              - destination: 0.0.0.0/0
                ports: '53'
                protocol: udp
            install_buildpacks:
            ## Order is important here
            - name: staticfile_buildpack
              package: staticfile-buildpack-cflinuxfs3
            - name: java_buildpack
              package: java-buildpack-cflinuxfs3
            - name: ruby_buildpack
              package: ruby-buildpack-cflinuxfs3
            - name: dotnet_core_buildpack
              package: dotnet-core-buildpack-cflinuxfs3
            - name: nodejs_buildpack
              package: nodejs-buildpack-cflinuxfs3
            - name: go_buildpack
              package: go-buildpack-cflinuxfs3
            - name: python_buildpack
              package: python-buildpack-cflinuxfs3
            - name: php_buildpack
              package: php-buildpack-cflinuxfs3
            - name: nginx_buildpack
              package: nginx-buildpack-cflinuxfs3
            - name: r_buildpack
              package: r-buildpack-cflinuxfs3
            - name: binary_buildpack
              package: binary-buildpack-cflinuxfs3
            db_encryption_key: "((cc_db_encryption_key))"
            database_encryption: &cc-database-encryption
              current_key_label: "encryption_key_0"
              keys:
                encryption_key_0: "((cc_db_encryption_key))"
            bulk_api_password: "((cc_bulk_api_password))"
            internal_api_password: "((cc_internal_api_password))"
            staging_upload_user: staging_user
            staging_upload_password: "((cc_staging_upload_password))"
            temporary_use_logcache: true
            logcache_tls:
              private_key: "((cc_logcache_tls.private_key))"
              certificate: "((cc_logcache_tls.certificate))"
            buildpacks: &blobstore-properties
              blobstore_type: webdav
              webdav_config:
                ca_cert: "((blobstore_tls.ca))"
                blobstore_timeout: 5
                password: "((blobstore_admin_users_password))"
                private_endpoint: https://blobstore.service.cf.internal:4443
                public_endpoint: https://blobstore.((system_domain))
                username: blobstore-user
            resource_pool: *blobstore-properties
            packages: *blobstore-properties
            droplets: *blobstore-properties
            mutual_tls: &cc_mutual_tls
              ca_cert: "((cc_tls.ca))"
              public_cert: "((cc_tls.certificate))"
              private_key: "((cc_tls.private_key))"
            public_tls:
              ca_cert: "((cc_public_tls.ca))"
              certificate: "((cc_public_tls.certificate))"
              private_key: "((cc_public_tls.private_key))"
          ccdb: &ccdb
            address: sql-db.service.cf.internal
            databases:
            - name: cloud_controller
              tag: cc
            db_scheme: mysql
            port: 3306
            roles:
            - name: cloud_controller
              password: "((cc_database_password))"
              tag: admin
            ca_cert: "((mysql_server_certificate.ca))"
      - name: binary-buildpack
        release: binary-buildpack
      - name: dotnet-core-buildpack
        release: dotnet-core-buildpack
      - name: go-buildpack
        release: go-buildpack
      - name: java-buildpack
        release: java-buildpack
      - name: nodejs-buildpack
        release: nodejs-buildpack
      - name: nginx-buildpack
        release: nginx-buildpack
      - name: r-buildpack
        release: r-buildpack
      - name: php-buildpack
        release: php-buildpack
      - name: python-buildpack
        release: python-buildpack
      - name: ruby-buildpack
        release: ruby-buildpack
      - name: staticfile-buildpack
        release: staticfile-buildpack
      - name: route_registrar
        release: routing
        properties:
          route_registrar:
            routes:
            - name: api
              registration_interval: 10s
              port: 9022
              tls_port: 9024
              server_cert_domain_san: "api.((system_domain))"
              tags:
                component: CloudController
              uris:
              - api.((system_domain))
              health_check:
                name: api-health-check
                script_path: "/var/vcap/jobs/cloud_controller_ng/bin/cloud_controller_ng_health_check"
                timeout: 6s
            - name: policy-server
              tls_port: 4002
              server_cert_domain_san: "api.((system_domain))"
              registration_interval: 20s
              uris:
              - api.((system_domain))/networking
      - name: statsd_injector
        release: statsd-injector
        properties: *statsd_injector_properties
      - name: file_server
        release: diego
        properties:
          bpm:
            enabled: true
          enable_consul_service_registration: false
          logging:
            format:
              timestamp: "rfc3339"
          loggregator: *diego_loggregator_client_properties
      - name: routing-api
        release: routing
        properties:
          routing_api:
            enabled_api_endpoints: "both"
            mtls_ca: "((routing_api_tls_client.ca))"
            mtls_server_cert: "((routing_api_tls.certificate))"
            mtls_server_key: "((routing_api_tls.private_key))"
            mtls_client_cert: "((routing_api_tls_client.certificate))"
            mtls_client_key: "((routing_api_tls_client.private_key))"
            skip_consul_lock: true
            system_domain: "((system_domain))"
            router_groups:
            - name: default-tcp
              type: tcp
              reservable_ports: 1024-1033
            sqldb:
              host: sql-db.service.cf.internal
              type: mysql
              port: 3306
              schema: routing-api
              username: routing-api
              password: "((routing_api_database_password))"
              ca_cert: "((mysql_server_certificate.ca))"
            locket:
              api_location: "locket.service.cf.internal:8891"
              ca_cert: "((diego_locket_client.ca))"
              client_cert: "((diego_locket_client.certificate))"
              client_key: "((diego_locket_client.private_key))"
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            tls_port: 8443
      - name: policy-server
        release: cf-networking
        properties:
          uaa_client_secret: ((uaa_clients_network_policy_secret))
          uaa_ca: ((uaa_ssl.ca))
          enable_space_developer_self_service: true
          enable_tls: true
          database:
            type: mysql
            username: network_policy
            password: ((network_policy_database_password))
            host: sql-db.service.cf.internal
            port: 3306
            name: network_policy
            ca_cert: "((mysql_server_certificate.ca))"
            require_ssl: true
          server_cert: ((network_policy_server_external.certificate))
          server_key: ((network_policy_server_external.private_key))
      - name: policy-server-internal
        release: cf-networking
        properties:
          ca_cert: ((network_policy_server.ca))
          server_cert: ((network_policy_server.certificate))
          server_key: ((network_policy_server.private_key))
      - name: cc_uploader
        release: capi
        properties:
          capi:
            cc_uploader:
              cc:
                ca_cert: "((cc_bridge_cc_uploader.ca))"
                client_cert: "((cc_bridge_cc_uploader.certificate))"
                client_key: "((cc_bridge_cc_uploader.private_key))"
              mutual_tls:
                ca_cert: "((cc_bridge_cc_uploader_server.ca))"
                server_cert: "((cc_bridge_cc_uploader_server.certificate))"
                server_key: "((cc_bridge_cc_uploader_server.private_key))"
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics
    - name: cc-worker
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: cloud_controller_worker
        release: capi
        properties:
          cc:
            db_encryption_key: "((cc_db_encryption_key))"
            database_encryption: *cc-database-encryption
            internal_api_password: "((cc_internal_api_password))"
            staging_upload_user: staging_user
            staging_upload_password: "((cc_staging_upload_password))"
            resource_pool: *blobstore-properties
            packages: *blobstore-properties
            droplets: *blobstore-properties
            buildpacks: *blobstore-properties
            mutual_tls: *cc_mutual_tls
          ccdb: *ccdb
          system_domain: "((system_domain))"
          routing_api: *routing_api
          ssl:
            skip_cert_verify: true
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            clients:
              cc-service-dashboards:
                secret: "((uaa_clients_cc-service-dashboards_secret))"
              cc_routing:
                secret: "((uaa_clients_cc-routing_secret))"
    - name: scheduler
      azs:
      - z1
      - z2
      instances: 2
      migrated_from:
      - {name: cc-bridge}
      - {name: cc-clock}
      - {name: diego-brain}
      vm_type: minimal
      vm_extensions:
      - diego-ssh-proxy-network-properties
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: cfdot
        release: diego
        properties:
          tls: *cfdot_tls_client_properties
      - name: auctioneer
        release: diego
        properties:
          bpm:
            enabled: true
          diego:
            auctioneer:
              bbs: &diego_bbs_client_properties
                ca_cert: "((diego_bbs_client.ca))"
                client_cert: "((diego_bbs_client.certificate))"
                client_key: "((diego_bbs_client.private_key))"
              ca_cert: "((diego_auctioneer_server.ca))"
              rep:
                require_tls: true
                ca_cert: "((diego_rep_client.ca))"
                client_cert: "((diego_rep_client.certificate))"
                client_key: "((diego_rep_client.private_key))"
              server_cert: "((diego_auctioneer_server.certificate))"
              server_key: "((diego_auctioneer_server.private_key))"
              skip_consul_lock: true
          enable_consul_service_registration: false
          loggregator: *diego_loggregator_client_properties
          logging:
            format:
              timestamp: "rfc3339"
      - name: cloud_controller_clock
        release: capi
        properties:
          cc:
            db_encryption_key: "((cc_db_encryption_key))"
            database_encryption: *cc-database-encryption
            internal_api_password: "((cc_internal_api_password))"
            staging_upload_user: staging_user
            staging_upload_password: "((cc_staging_upload_password))"
            resource_pool: *blobstore-properties
            packages: *blobstore-properties
            droplets: *blobstore-properties
            buildpacks: *blobstore-properties
            mutual_tls: *cc_mutual_tls
          ccdb: *ccdb
          system_domain: "((system_domain))"
          routing_api: *routing_api
          ssl:
            skip_cert_verify: true
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            clients:
              cc-service-dashboards:
                secret: "((uaa_clients_cc-service-dashboards_secret))"
              cc_routing:
                secret: "((uaa_clients_cc-routing_secret))"
            ssl:
              port: 8443
      - name: cc_deployment_updater
        release: capi
        properties:
          cc:
            db_encryption_key: ((cc_db_encryption_key))
            mutual_tls:
              ca_cert: "((cc_tls.ca))"
              private_key: "((cc_tls.private_key))"
              public_cert: "((cc_tls.certificate))"
          ccdb:
            databases:
            - name: cloud_controller
              tag: cc
            db_scheme: mysql
            port: 3306
            roles:
            - name: cloud_controller
              password: ((cc_database_password))
              tag: admin
      - name: service-discovery-controller
        properties:
          dnshttps:
            client:
              ca: ((cf_app_sd_server_tls.ca))
            server:
              tls: ((cf_app_sd_server_tls))
        release: cf-networking
      - name: statsd_injector
        release: statsd-injector
        properties: *statsd_injector_properties
      - name: tps
        release: capi
        properties:
          capi:
            tps:
              bbs: *diego_bbs_client_properties
              watcher:
                locket:
                  api_location: "locket.service.cf.internal:8891"
                skip_consul_lock: true
              cc:
                ca_cert: "((cc_bridge_tps.ca))"
                client_cert: "((cc_bridge_tps.certificate))"
                client_key: "((cc_bridge_tps.private_key))"
      - name: ssh_proxy
        release: diego
        properties:
          bpm:
            enabled: true
          diego:
            ssh_proxy:
              enable_cf_auth: true
              host_key: "((diego_ssh_proxy_host_key.private_key))"
              uaa_secret: "((uaa_clients_ssh-proxy_secret))"
              uaa:
                ca_cert: "((uaa_ssl.ca))"
              bbs: *diego_bbs_client_properties
              disable_healthcheck_server: true
          backends:
            tls:
              enabled: true
              ca_certificates:
              - ((diego_instance_identity_ca.ca))
              client_certificate: ((ssh_proxy_backends_tls.certificate))
              client_private_key: ((ssh_proxy_backends_tls.private_key))
          enable_consul_service_registration: false
          loggregator: *diego_loggregator_client_properties
          logging:
            format:
              timestamp: "rfc3339"
      - name: loggr-syslog-binding-cache
        release: loggregator-agent
        properties:
          external_port: 9000
          tls:
            ca_cert: "((binding_cache_tls.ca))"
            cert: "((binding_cache_tls.certificate))"
            key: "((binding_cache_tls.private_key))"
            cn: "binding-cache"
          api:
            tls:
              ca_cert: "((cc_tls.ca))"
              cert: "((binding_cache_api_tls.certificate))"
              key: "((binding_cache_api_tls.private_key))"
              cn: "cloud-controller-ng.service.cf.internal"
          metrics:
            ca_cert: "((loggr_syslog_binding_cache_metrics_tls.ca))"
            cert: "((loggr_syslog_binding_cache_metrics_tls.certificate))"
            key: "((loggr_syslog_binding_cache_metrics_tls.private_key))"
            server_name: loggr_syslog_binding_cache_metrics
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics
    - name: router
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      vm_extensions:
      - cf-router-network-properties
      stemcell: default
      update:
        serial: true
      networks:
      - name: default
      jobs:
      - name: gorouter
        release: routing
        properties:
          router:
            enable_ssl: true
            tls_pem:
            - cert_chain: "((router_ssl.certificate))"
              private_key: "((router_ssl.private_key))"
            ca_certs: |
              ((diego_instance_identity_ca.ca))
              ((cc_tls.ca))
              ((uaa_ssl.ca))
              ((network_policy_server_external.ca))
            backends:
              cert_chain: ((gorouter_backend_tls.certificate))
              private_key: ((gorouter_backend_tls.private_key))
            status:
              password: "((router_status_password))"
              user: router-status
            route_services_secret: "((router_route_services_secret))"
            tracing:
              enable_zipkin: true
          routing_api:
            enabled: true
          uaa:
            clients:
              gorouter:
                secret: "((uaa_clients_gorouter_secret))"
            ca_cert: "((uaa_ssl.ca))"
            ssl:
              port: 8443
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics
    - name: tcp-router
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      stemcell: default
      vm_extensions:
      - cf-tcp-router-network-properties
      networks:
      - name: default
      jobs:
      - name: tcp_router
        release: routing
        properties:
          tcp_router:
            oauth_secret: "((uaa_clients_tcp_router_secret))"
            router_group: default-tcp
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            tls_port: 8443
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics
    - name: doppler
      azs:
      - z1
      - z2
      instances: 4
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: doppler
        release: loggregator
        provides:
          doppler: {as: doppler, shared: true}
        properties:
          loggregator:
            tls:
              ca_cert: "((loggregator_tls_doppler.ca))"
              doppler:
                cert: "((loggregator_tls_doppler.certificate))"
                key: "((loggregator_tls_doppler.private_key))"
      - name: log-cache
        provides:
          log-cache: {shared: true}
        properties:
          metrics:
            ca_cert: "((log_cache_metrics_tls.ca))"
            cert: "((log_cache_metrics_tls.certificate))"
            key: "((log_cache_metrics_tls.private_key))"
            server_name: log_cache_metrics
          health_addr: localhost:6060
          tls:
            ca_cert: ((log_cache.ca))
            cert: ((log_cache.certificate))
            key: ((log_cache.private_key))
        release: log-cache
      - name: log-cache-gateway
        properties:
          gateway_addr: localhost:8081
          proxy_cert: "((log_cache_proxy_tls.certificate))"
          proxy_key: "((log_cache_proxy_tls.private_key))"
          metrics:
            ca_cert: "((log_cache_gateway_metrics_tls.ca))"
            cert: "((log_cache_gateway_metrics_tls.certificate))"
            key: "((log_cache_gateway_metrics_tls.private_key))"
            server_name: log_cache_gateway_metrics
        release: log-cache
      - consumes:
          reverse_log_proxy: {from: reverse_log_proxy}
        name: log-cache-nozzle
        properties:
          logs_provider:
            tls:
              ca_cert: ((logs_provider.ca))
              cert: ((logs_provider.certificate))
              key: ((logs_provider.private_key))
        release: log-cache
      - name: route_registrar
        properties:
          route_registrar:
            routes:
            - name: log-cache-reverse-proxy
              port: 8083
              tls_port: 8083
              registration_interval: 20s
              server_cert_domain_san: log-cache.((system_domain))
              uris:
              - log-cache.((system_domain))
              - '*.log-cache.((system_domain))'
        release: routing
      - name: log-cache-cf-auth-proxy
        properties:
          metrics:
            ca_cert: "((log_cache_cf_auth_proxy_metrics_tls.ca))"
            cert: "((log_cache_cf_auth_proxy_metrics_tls.certificate))"
            key: "((log_cache_cf_auth_proxy_metrics_tls.private_key))"
            server_name: log_cache_cf_auth_proxy_metrics
          cc:
            ca_cert: ((cc_tls.ca))
            common_name: cloud-controller-ng.service.cf.internal
          proxy_ca_cert: "((log_cache.ca))"
          proxy_port: 8083
          external_cert: ((logcache_ssl.certificate))
          external_key: ((logcache_ssl.private_key))
          uaa:
            ca_cert: ((uaa_ssl.ca))
            client_id: doppler
            client_secret: ((uaa_clients_doppler_secret))
            internal_addr: https://uaa.service.cf.internal:8443
        release: log-cache
    - name: diego-cell
      azs:
      - z1
      - z2
      instances: 3
      vm_type: small-highmem
      vm_extensions:
      - 100GB_ephemeral_disk
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: bosh-dns-adapter
        properties:
          internal_domains: ["apps.internal."]
          dnshttps:
            client:
              tls: ((cf_app_sd_client_tls))
            server:
              ca: ((cf_app_sd_client_tls.ca))
        release: cf-networking
      - name: cflinuxfs3-rootfs-setup
        release: cflinuxfs3
        properties:
          cflinuxfs3-rootfs:
            trusted_certs:
            - ((diego_instance_identity_ca.ca))
            - ((credhub_tls.ca))
            - ((uaa_ssl.ca))
      - name: garden
        release: garden-runc
        properties:
          garden:
            containerd_mode: true
            cleanup_process_dirs_on_wait: true
            debug_listen_address: 127.0.0.1:17019
            default_container_grace_time: 0
            destroy_containers_on_start: true
            deny_networks:
            - 0.0.0.0/0
            network_plugin: /var/vcap/packages/runc-cni/bin/garden-external-networker
            network_plugin_extra_args:
            - --configFile=/var/vcap/jobs/garden-cni/config/adapter.json
          logging:
            format:
              timestamp: "rfc3339"
      - name: rep
        release: diego
        properties:
          bpm:
            enabled: true
          diego:
            executor:
              instance_identity_ca_cert: ((diego_instance_identity_ca.certificate))
              instance_identity_key: ((diego_instance_identity_ca.private_key))
            rep:
              preloaded_rootfses:
              - cflinuxfs3:/var/vcap/packages/cflinuxfs3/rootfs.tar
          containers:
            proxy:
              enabled: true
              require_and_verify_client_certificates: true
              trusted_ca_certificates:
              - ((gorouter_backend_tls.ca))
              - ((ssh_proxy_backends_tls.ca))
              verify_subject_alt_name:
              - gorouter.service.cf.internal
              - ssh-proxy.service.cf.internal
            trusted_ca_certificates:
            - ((diego_instance_identity_ca.ca))
            - ((credhub_tls.ca))
            - ((uaa_ssl.ca))
          enable_consul_service_registration: false
          enable_declarative_healthcheck: true
          loggregator: *diego_loggregator_client_properties
          tls:
            ca_cert: "((diego_rep_agent_v2.ca))"
            cert: "((diego_rep_agent_v2.certificate))"
            key: "((diego_rep_agent_v2.private_key))"
          logging:
            format:
              timestamp: "rfc3339"
      - name: cfdot
        release: diego
        properties:
          tls: *cfdot_tls_client_properties
      - name: route_emitter
        release: diego
        consumes:
          nats:
            ip_addresses: false
          nats-tls:
            ip_addresses: false
        properties:
          bpm:
            enabled: true
          loggregator: *diego_loggregator_client_properties
          diego:
            route_emitter:
              local_mode: true
              bbs:
                ca_cert: "((diego_bbs_client.ca))"
                client_cert: "((diego_bbs_client.certificate))"
                client_key: "((diego_bbs_client.private_key))"
              nats:
                tls:
                  enabled: true
                  client_cert: "((nats_client_cert.certificate))"
                  client_key: "((nats_client_cert.private_key))"
          tcp:
            enabled: true
          uaa:
            ca_cert: "((uaa_ssl.ca))"
            client_secret: "((uaa_clients_tcp_emitter_secret))"
          logging:
            format:
              timestamp: "rfc3339"
          internal_routes:
            enabled: true
      - name: garden-cni
        release: cf-networking
        properties:
          cni_plugin_dir: /var/vcap/packages/silk-cni/bin
          cni_config_dir: /var/vcap/jobs/silk-cni/config/cni
      - name: netmon
        release: silk
      - name: vxlan-policy-agent
        release: silk
        properties:
          ca_cert: ((network_policy_client.ca))
          client_cert: ((network_policy_client.certificate))
          client_key: ((network_policy_client.private_key))
      - name: silk-daemon
        release: silk
        properties:
          ca_cert: ((silk_daemon.ca))
          client_cert: ((silk_daemon.certificate))
          client_key: ((silk_daemon.private_key))
      - name: silk-cni
        release: silk
        properties:
          dns_servers:
          - 169.254.0.2
      - name: loggr-udp-forwarder
        release: loggregator-agent
        properties:
          loggregator:
            tls:
              ca: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
          metrics:
            ca_cert: "((loggr_udp_forwarder_tls.ca))"
            cert: "((loggr_udp_forwarder_tls.certificate))"
            key: "((loggr_udp_forwarder_tls.private_key))"
            server_name: loggr_udp_forwarder_metrics
    - name: log-api
      azs:
      - z1
      - z2
      instances: 2
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: loggregator_trafficcontroller
        release: loggregator
        consumes:
          doppler: {from: doppler}
        properties:
          uaa:
            internal_url: https://uaa.service.cf.internal:8443
            ca_cert: "((uaa_ssl.ca))"
          loggregator:
            outgoing_cert: "((loggregator_trafficcontroller_tls.certificate))"
            outgoing_key: "((loggregator_trafficcontroller_tls.private_key))"
            tls:
              cc_trafficcontroller:
                cert: "((loggregator_tls_cc_tc.certificate))"
                key: "((loggregator_tls_cc_tc.private_key))"
              ca_cert: "((loggregator_tls_tc.ca))"
              trafficcontroller:
                cert: "((loggregator_tls_tc.certificate))"
                key: "((loggregator_tls_tc.private_key))"
            uaa:
              client_secret: "((uaa_clients_doppler_secret))"
          system_domain: "((system_domain))"
          ssl:
            skip_cert_verify: true
          cc:
            internal_service_hostname: "cloud-controller-ng.service.cf.internal"
            tls_port: 9023
            mutual_tls:
              ca_cert: "((cc_tls.ca))"
      - name: reverse_log_proxy
        release: loggregator
        provides:
          reverse_log_proxy: {as: reverse_log_proxy, shared: true}
        properties:
          loggregator:
            tls:
              ca_cert: "((loggregator_tls_rlp.ca))"
              reverse_log_proxy:
                cert: "((loggregator_tls_rlp.certificate))"
                key: "((loggregator_tls_rlp.private_key))"
      - name: reverse_log_proxy_gateway
        release: loggregator
        properties:
          http:
            address: "0.0.0.0:8088"
            cert: "((loggregator_rlp_gateway_tls.certificate))"
            key: "((loggregator_rlp_gateway_tls.private_key))"
          logs_provider:
            ca_cert: "((loggregator_rlp_gateway.ca))"
            client_cert: "((loggregator_rlp_gateway.certificate))"
            client_key: "((loggregator_rlp_gateway.private_key))"
          cc:
            capi_internal_addr: https://cloud-controller-ng.service.cf.internal:9023
            ca_cert: ((loggregator_rlp_gateway_tls_cc.ca))
            cert: ((loggregator_rlp_gateway_tls_cc.certificate))
            key: ((loggregator_rlp_gateway_tls_cc.private_key))
            common_name: cloud-controller-ng.service.cf.internal
          uaa:
            ca_cert: ((uaa_ssl.ca))
            client_id: doppler
            client_secret: ((uaa_clients_doppler_secret))
            internal_addr: https://uaa.service.cf.internal:8443
          metrics:
            ca_cert: "((rlp_gateway_metrics_tls.ca))"
            cert: "((rlp_gateway_metrics_tls.certificate))"
            key: "((rlp_gateway_metrics_tls.private_key))"
            server_name: rlp_gateway_metrics
      - name: route_registrar
        release: routing
        properties:
          route_registrar:
            routes:
            - name: doppler
              tls_port: 8081
              registration_interval: 20s
              server_cert_domain_san: doppler.((system_domain))
              uris:
              - doppler.((system_domain))
              - "*.doppler.((system_domain))"
            - name: rlp-gateway
              tls_port: 8088
              server_cert_domain_san: log-stream.((system_domain))
              registration_interval: 20s
              uris:
              - log-stream.((system_domain))
              - "*.log-stream.((system_domain))"
    - name: credhub
      azs:
      - z1
      - z2
      instances: 2
      networks:
      - name: default
      stemcell: default
      vm_type: minimal
      jobs:
      - name: credhub
        properties:
          credhub:
            authentication:
              mutual_tls:
                trusted_cas:
                - ((diego_instance_identity_ca.ca))
              uaa:
                ca_certs:
                - ((uaa_ssl.ca))
                url: https://uaa.service.cf.internal:8443
            authorization:
              acls:
                enabled: true
              permissions:
              - path: /*
                actors: ["uaa-client:credhub_admin_client"]
                operations: [read, write, delete, read_acl, write_acl]
              - path: /*
                actors: ["uaa-client:cc_service_key_client"]
                operations: [read]
            ca_certificate: |
              ((credhub_tls.ca))
            data_storage:
              database: credhub
              host: sql-db.service.cf.internal
              password: ((credhub_database_password))
              port: 3306
              type: mysql
              username: credhub
              tls_ca: "((mysql_server_certificate.ca))"
            encryption:
              keys:
              - active: true
                key_properties:
                  encryption_password: ((credhub_encryption_password))
                provider_name: internal-provider
              providers:
              - name: internal-provider
                type: internal
            internal_url: https://credhub.service.cf.internal
            tls: ((credhub_tls))
        release: credhub
    - name: rotate-cc-database-key
      azs:
      - z1
      instances: 1
      lifecycle: errand
      vm_type: minimal
      stemcell: default
      networks:
      - name: default
      jobs:
      - name: rotate_cc_database_key
        release: capi
        properties: {}

    variables:
    - name: blobstore_admin_users_password
      type: password
    - name: blobstore_secure_link_secret
      type: password
    - name: cc_bulk_api_password
      type: password
    - name: cc_db_encryption_key
      type: password
    - name: cc_internal_api_password
      type: password
    - name: cc_staging_upload_password
      type: password
    - name: cf_app_sd_ca
      options:
        common_name: service-discovery-controller.service.cf.internal
        is_ca: true
      type: certificate
    - name: cf_app_sd_client_tls
      options:
        ca: cf_app_sd_ca
        common_name: service-discovery-controller.service.cf.internal
        extended_key_usage:
        - client_auth
      type: certificate
    - name: cf_app_sd_server_tls
      options:
        ca: cf_app_sd_ca
        common_name: service-discovery-controller.service.cf.internal
        extended_key_usage:
        - server_auth
      type: certificate
    - name: cf_mysql_mysql_admin_password
      type: password
    - name: cf_mysql_mysql_cluster_health_password
      type: password
    - name: cf_mysql_mysql_galera_healthcheck_endpoint_password
      type: password
    - name: cf_mysql_mysql_galera_healthcheck_password
      type: password
    - name: cf_mysql_proxy_api_password
      type: password
    - name: cc_database_password
      type: password
    - name: credhub_database_password
      type: password
    - name: diego_database_password
      type: password
    - name: uaa_database_password
      type: password
    - name: routing_api_database_password
      type: password
    - name: network_policy_database_password
      type: password
    - name: network_connectivity_database_password
      type: password
    - name: uaa_default_encryption_passphrase
      type: password
    - name: silk_ca
      type: certificate
      options:
        is_ca: true
        common_name: silk-ca
    - name: silk_controller
      type: certificate
      options:
        ca: silk_ca
        common_name: silk-controller.service.cf.internal
        extended_key_usage:
        - server_auth
    - name: silk_daemon
      type: certificate
      options:
        ca: silk_ca
        common_name: silk-daemon
        extended_key_usage:
        - client_auth
    - name: network_policy_ca
      type: certificate
      options:
        is_ca: true
        common_name: networkPolicyCA
    - name: network_policy_server_external
      type: certificate
      options:
        ca: network_policy_ca
        common_name: "api.((system_domain))"
        alternative_names:
        - "api.((system_domain))"
        extended_key_usage:
        - server_auth
    - name: network_policy_server
      type: certificate
      options:
        ca: network_policy_ca
        common_name: policy-server.service.cf.internal
        extended_key_usage:
        - server_auth
    - name: network_policy_client
      type: certificate
      options:
        ca: network_policy_ca
        common_name: clientName
        extended_key_usage:
        - client_auth
    - name: uaa_clients_routing_api_client_secret
      type: password
    - name: uaa_clients_tcp_emitter_secret
      type: password
    - name: nats_password
      type: password
    - name: router_status_password
      type: password
    - name: cf_admin_password
      type: password
    - name: router_route_services_secret
      type: password
    - name: uaa_admin_client_secret
      type: password
    - name: uaa_clients_cc-routing_secret
      type: password
    - name: uaa_clients_cc-service-dashboards_secret
      type: password
    - name: uaa_clients_cc_service_key_client_secret
      type: password
    - name: uaa_clients_cf_smoke_tests_secret
      type: password
    - name: uaa_clients_cloud_controller_username_lookup_secret
      type: password
    - name: uaa_clients_doppler_secret
      type: password
    - name: uaa_clients_gorouter_secret
      type: password
    - name: uaa_clients_network_policy_secret
      type: password
    - name: uaa_clients_ssh-proxy_secret
      type: password
    - name: uaa_clients_tcp_router_secret
      type: password
    - name: diego_bbs_encryption_keys_passphrase
      type: password
    - name: credhub_encryption_password
      type: password
    - name: credhub_admin_client_secret
      type: password
    - name: diego_ssh_proxy_host_key
      type: ssh
    - name: uaa_jwt_signing_key
      type: rsa
    - name: service_cf_internal_ca
      type: certificate
      options:
        is_ca: true
        common_name: internalCA
    - name: blobstore_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: blobstore.service.cf.internal
    - name: diego_auctioneer_client
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: auctioneer client
        extended_key_usage:
        - client_auth
    - name: diego_auctioneer_server
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: auctioneer.service.cf.internal
        extended_key_usage:
        - server_auth
        alternative_names:
        - "*.auctioneer.service.cf.internal"
        - auctioneer.service.cf.internal
    - name: diego_bbs_client
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: bbs client
        extended_key_usage:
        - client_auth
    - name: diego_bbs_server
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: bbs.service.cf.internal
        extended_key_usage:
        - server_auth
        - client_auth
        alternative_names:
        - "*.bbs.service.cf.internal"
        - bbs.service.cf.internal
    - name: diego_rep_client
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: rep client
        extended_key_usage:
        - client_auth
    - name: diego_rep_agent_v2
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: cell.service.cf.internal
        extended_key_usage:
        - client_auth
        - server_auth
        alternative_names:
        - "*.cell.service.cf.internal"
        - cell.service.cf.internal
        - 127.0.0.1
        - localhost
    - name: loggregator_ca
      type: certificate
      options:
        is_ca: true
        common_name: loggregatorCA
    - name: loggregator_tls_statsdinjector
      type: certificate
      options:
        ca: loggregator_ca
        common_name: statsdinjector
        extended_key_usage:
        - client_auth
    - name: loggregator_tls_agent
      type: certificate
      options:
        ca: loggregator_ca
        common_name: metron
        extended_key_usage:
        - client_auth
        - server_auth
    - name: loggregator_tls_doppler
      type: certificate
      options:
        ca: loggregator_ca
        common_name: doppler
        extended_key_usage:
        - client_auth
        - server_auth
    - name: loggregator_tls_tc
      type: certificate
      options:
        ca: loggregator_ca
        common_name: trafficcontroller
        extended_key_usage:
        - client_auth
        - server_auth
    - name: loggregator_tls_cc_tc
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: trafficcontroller
        extended_key_usage:
        - client_auth
    - name: loggregator_rlp_gateway_tls_cc
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: rlp-gateway
        extended_key_usage:
        - client_auth
    - name: loggregator_tls_rlp
      type: certificate
      options:
        ca: loggregator_ca
        common_name: reverselogproxy
        extended_key_usage:
        - client_auth
        - server_auth
    - name: loggregator_rlp_gateway
      type: certificate
      options:
        ca: loggregator_ca
        common_name: rlp_gateway
        extended_key_usage:
        - client_auth
    - name: logs_provider
      options:
        ca: loggregator_ca
        common_name: log-cache
        extended_key_usage:
        - client_auth
        - server_auth
      type: certificate
    - name: log_cache_ca
      options:
        common_name: log-cache
        is_ca: true
      type: certificate
    - name: log_cache
      options:
        alternative_names:
        - log_cache
        - log-cache
        - logcache
        ca: log_cache_ca
        common_name: log-cache
        extended_key_usage:
        - client_auth
        - server_auth
      type: certificate
    - name: log_cache_to_loggregator_agent
      options:
        ca: loggregator_ca
        common_name: log-cache
        extended_key_usage:
        - client_auth
      type: certificate
    - name: cc_logcache_tls
      type: certificate
      options:
        ca: log_cache_ca
        common_name: "api.((system_domain))"
        alternative_names:
        - "api.((system_domain))"
        - cloud-controller-ng.service.cf.internal
    - name: logcache_ssl
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: log-cache
        alternative_names:
        - log-cache.((system_domain))
        - "*.log-cache.((system_domain))"
    - name: log_cache_proxy_tls
      type: certificate
      options:
        ca: log_cache_ca
        common_name: localhost
    - name: router_ca
      type: certificate
      options:
        is_ca: true
        common_name: routerCA
    - name: router_ssl
      type: certificate
      options:
        ca: router_ca
        common_name: routerSSL
        alternative_names:
        - "((system_domain))"
        - "*.((system_domain))"
    - name: routing_api_ca
      type: certificate
      options:
        common_name: routing_api
        is_ca: true
    - name: routing_api_tls
      type: certificate
      options:
        ca: routing_api_ca
        common_name: routing-api.service.cf.internal
        extended_key_usage:
          - server_auth
    - name: routing_api_tls_client
      type: certificate
      options:
        ca: routing_api_ca
        common_name: routing-api-client
        extended_key_usage:
          - client_auth
    - name: uaa_ca
      type: certificate
      options:
        is_ca: true
        common_name: uaaCA
    - name: uaa_ssl
      type: certificate
      options:
        ca: uaa_ca
        common_name: uaa.service.cf.internal
        alternative_names:
        - uaa.service.cf.internal
    - name: uaa_login_saml
      type: certificate
      options:
        ca: uaa_ca
        common_name: uaa_login_saml
    - name: cc_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: cloud-controller-ng.service.cf.internal
        extended_key_usage:
        - client_auth
        - server_auth
    - name: cc_public_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: "api.((system_domain))"
        alternative_names:
        - "api.((system_domain))"
        - cloud-controller-ng.service.cf.internal
    - name: cc_bridge_tps
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: tps_watcher
        extended_key_usage:
        - client_auth
    - name: cc_bridge_cc_uploader
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: cc_uploader
        extended_key_usage:
        - client_auth
    - name: cc_bridge_cc_uploader_server
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: cc-uploader.service.cf.internal
        extended_key_usage:
        - server_auth
    - name: diego_locket_server
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: locket.service.cf.internal
        extended_key_usage:
        - server_auth
        alternative_names:
        - "*.locket.service.cf.internal"
        - locket.service.cf.internal
    - name: diego_locket_client
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: locket client
        extended_key_usage:
        - client_auth
    - name: locket_database_password
      type: password
    - name: application_ca
      type: certificate
      options:
        common_name: appRootCA
        is_ca: true
    - name: diego_instance_identity_ca
      type: certificate
      options:
        ca: application_ca
        common_name: instanceIdentityCA
        is_ca: true
    - name: gorouter_backend_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        extended_key_usage:
        - client_auth
        common_name: gorouter_backend_tls
        alternative_names:
        - gorouter.service.cf.internal
    - name: credhub_ca
      type: certificate
      options:
        common_name: credhubServerCa
        is_ca: true
    - name: credhub_tls
      type: certificate
      options:
        ca: credhub_ca
        common_name: credhub.((system_domain))
        alternative_names:
        - credhub.service.cf.internal
        - credhub.((system_domain))
    - name: ssh_proxy_backends_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        extended_key_usage:
        - client_auth
        common_name: ssh_proxy_backends_tls
        alternative_names:
        - ssh-proxy.service.cf.internal
    - name: pxc_galera_ca
      type: certificate
      options:
        common_name: pxc_galera_ca
        is_ca: true
    - name: pxc_server_ca
      type: certificate
      options:
        common_name: pxc_server_ca
        is_ca: true
    - name: galera_server_certificate
      type: certificate
      options:
        ca: pxc_galera_ca
        common_name: galera_server_certificate
        extended_key_usage:
        - server_auth
        - client_auth
    - name: mysql_server_certificate
      type: certificate
      options:
        ca: pxc_server_ca
        common_name: sql-db.service.cf.internal

    - name: loggregator_rlp_gateway_tls
      type: certificate
      options:
        alternative_names:
        - log-stream.((system_domain))
        - log-api.service.cf.internal
        ca: service_cf_internal_ca
        common_name: log-stream.((system_domain))

    - name: loggregator_trafficcontroller_tls
      type: certificate
      options:
        alternative_names:
        - doppler.((system_domain))
        - log-api.service.cf.internal
        ca: service_cf_internal_ca
        common_name: doppler.((system_domain))

    - name: metric_scraper_ca
      type: certificate
      options:
        is_ca: true
        common_name: metricScraperCA

    - name: metrics_agent_tls
      options:
        ca: metric_scraper_ca
        common_name: metrics_agent
        extended_key_usage:
          - server_auth
      type: certificate
    - name: metrics_discovery_metrics_tls
      options:
        ca: metric_scraper_ca
        common_name: metrics_discovery_metrics
        extended_key_usage:
          - server_auth
      type: certificate
    - name: scrape_config_generator_metrics_tls
      options:
        ca: metric_scraper_ca
        common_name: scrape_config_generator_metrics
        extended_key_usage:
          - server_auth
      type: certificate

    - name: log_cache_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: log_cache_metrics
        extended_key_usage:
        - server_auth

    - name: log_cache_cf_auth_proxy_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: log_cache_cf_auth_proxy_metrics
        extended_key_usage:
        - server_auth

    - name: log_cache_gateway_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: log_cache_gateway_metrics
        extended_key_usage:
        - server_auth

    - name: forwarder_agent_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: forwarder_agent_metrics
        extended_key_usage:
        - server_auth

    - name: loggregator_agent_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: loggregator_agent_metrics
        extended_key_usage:
        - server_auth

    - name: loggr_udp_forwarder_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: loggr_udp_forwarder_metrics
        extended_key_usage:
        - server_auth

    - name: syslog_agent_api_tls
      type: certificate
      options:
        ca: loggregator_ca
        common_name: syslog-agent
        extended_key_usage:
        - client_auth

    - name: binding_cache_api_tls
      type: certificate
      options:
        ca: service_cf_internal_ca
        common_name: binding-cache
        extended_key_usage:
        - client_auth

    - name: binding_cache_tls
      type: certificate
      options:
        ca: loggregator_ca
        common_name: binding-cache
        extended_key_usage:
        - server_auth

    - name: syslog_agent_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: syslog_agent_metrics
        extended_key_usage:
        - server_auth

    - name: loggr_syslog_binding_cache_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: loggr_syslog_binding_cache_metrics
        extended_key_usage:
        - server_auth

    - name: prom_scraper_scrape_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: prom_scraper
        extended_key_usage:
        - client_auth

    - name: prom_scraper_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: prom_scraper_metrics
        extended_key_usage:
        - server_auth

    - name: rlp_gateway_metrics_tls
      type: certificate
      options:
        ca: metric_scraper_ca
        common_name: rlp_gateway_metrics
        extended_key_usage:
        - server_auth

    - name: nats_internal_ca
      type: certificate
      options:
        is_ca: true
        common_name: nats_internal

    - name: nats_internal_cert
      type: certificate
      options:
        ca: nats_internal_ca
        common_name: "*.nats.service.cf.internal"
        alternative_names:
        - "*.nats.service.cf.internal"
        - nats.service.cf.internal
        extended_key_usage:
        - client_auth
        - server_auth

    - name: nats_ca
      type: certificate
      options:
        is_ca: true
        common_name: nats

    - name: nats_client_cert
      type: certificate
      options:
        ca: nats_ca
        common_name: "nats_client"
        extended_key_usage:
        - client_auth

    - name: nats_server_cert
      type: certificate
      options:
        ca: nats_ca
        common_name: nats.service.cf.internal
        extended_key_usage:
        - server_auth
      consumes:
        alternative_name:
          from: nats-tls-address
          properties: { wildcard: true }

    releases:
    - name: binary-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/binary-buildpack-release?v=1.0.36
      version: 1.0.36
      sha1: 0269a613be68f988682bbf56504b78477965b1c4
    - name: bpm
      url: https://bosh.io/d/github.com/cloudfoundry/bpm-release?v=1.1.8
      version: 1.1.8
      sha1: c956394fce7e74f741e4ae8c256b480904ad5942
    - name: capi
      url: https://bosh.io/d/github.com/cloudfoundry/capi-release?v=1.96.0
      version: 1.96.0
      sha1: 879b50c2ba103826dd32c7e65d9eefc7797f67e7
    - name: cf-networking
      url: https://bosh.io/d/github.com/cloudfoundry/cf-networking-release?v=2.31.0
      version: 2.31.0
      sha1: f27406853aee40c38615d61cf648936c0ef63d2f
    - name: cf-smoke-tests
      url: https://bosh.io/d/github.com/cloudfoundry/cf-smoke-tests-release?v=40.0.134
      version: 40.0.134
      sha1: 0dd5720a87878cac9bb7c1f903f8cbf7ef0124ce
    - name: cflinuxfs3
      url: https://bosh.io/d/github.com/cloudfoundry/cflinuxfs3-release?v=0.200.0
      version: 0.200.0
      sha1: 532e6a42ce290bdd5c0c1ef3a2366f26cf827c65
    - name: credhub
      url: https://bosh.io/d/github.com/pivotal-cf/credhub-release?v=2.8.0
      version: 2.8.0
      sha1: 3a9732bab2fa80bb9431941193b6569ef29af491
    - name: diego
      url: https://bosh.io/d/github.com/cloudfoundry/diego-release?v=2.47.0
      version: 2.47.0
      sha1: 836fd16bc282ea445e4d9cb79e14e3bc1b10d240
    - name: dotnet-core-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/dotnet-core-buildpack-release?v=2.3.12
      version: 2.3.12
      sha1: 8b19b70b8391b85bc796e7954fd8fe746bffa62f
    - name: garden-runc
      url: https://bosh.io/d/github.com/cloudfoundry/garden-runc-release?v=1.19.14
      version: 1.19.14
      sha1: b3a949f55d8e8514267cf48a242b8321183ace6c
    - name: go-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/go-buildpack-release?v=1.9.14
      version: 1.9.14
      sha1: ebe497c9fe0a07bb86597fa500a3d3865ece18d6
    - name: java-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/java-buildpack-release?v=4.32
      version: "4.32"
      sha1: 411b208b14f39c843da62c804e0850f860957b74
    - name: loggregator
      url: https://bosh.io/d/github.com/cloudfoundry/loggregator-release?v=106.3.10
      version: 106.3.10
      sha1: 31992561334a0c2b42ea830b3af90d012172e7e5
    - name: metrics-discovery
      url: https://bosh.io/d/github.com/cloudfoundry/metrics-discovery-release?v=3.0.1
      version: 3.0.1
      sha1: 4219b58972d20f6fccf1a4a167d915e34d86ee8a
    - name: nats
      url: https://bosh.io/d/github.com/cloudfoundry/nats-release?v=34
      version: "34"
      sha1: 0d7f4c3203c926e79d85d07b1ac215d73c9268c3
    - name: nginx-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/nginx-buildpack-release?v=1.1.11
      version: 1.1.11
      sha1: d2cd1d7cafe44477474accaf2c8aafc7c79380ab
    - name: r-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/r-buildpack-release?v=1.1.7
      version: 1.1.7
      sha1: c7ee8762d9ce8da4882c924cb46e77bef3b2fafc
    - name: nodejs-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/nodejs-buildpack-release?v=1.7.24
      version: 1.7.24
      sha1: ea8f668e442d1a6c1a1be49f8bc52c9d98516871
    - name: php-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/php-buildpack-release?v=4.4.18
      version: 4.4.18
      sha1: d14454c7c21be06236c5ca15cbfb6643c62b7f91
    - name: pxc
      url: https://bosh.io/d/github.com/cloudfoundry-incubator/pxc-release?v=0.28.0
      version: 0.28.0
      sha1: b09790e0d9df109e84416ef28393438846af9f9f
    - name: python-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/python-buildpack-release?v=1.7.16
      version: 1.7.16
      sha1: 9259aa43ad6b43699d886380d03a7ffd80509f97
    - name: routing
      url: https://bosh.io/d/github.com/cloudfoundry/routing-release?v=0.203.0
      version: 0.203.0
      sha1: f4c081c39f64c368fab7a2553b074e8850d1f5f5
    - name: ruby-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/ruby-buildpack-release?v=1.8.21
      version: 1.8.21
      sha1: 8e7c63348ec52c70e5dadc8de4b42e2289f99e81
    - name: silk
      url: https://bosh.io/d/github.com/cloudfoundry/silk-release?v=2.31.0
      version: 2.31.0
      sha1: 8935189b632a8c805e46b8079f5c459d6b70784f
    - name: staticfile-buildpack
      url: https://bosh.io/d/github.com/cloudfoundry/staticfile-buildpack-release?v=1.5.9
      version: 1.5.9
      sha1: 67dfff58d2efc40e632f70db6a602c31ee491f6a
    - name: statsd-injector
      url: https://bosh.io/d/github.com/cloudfoundry/statsd-injector-release?v=1.11.15
      version: 1.11.15
      sha1: a0a2d33c6ab7d8fec8c017ea6f2c5a344af1407c
    - name: uaa
      url: https://bosh.io/d/github.com/cloudfoundry/uaa-release?v=74.23.0
      version: 74.23.0
      sha1: 7137d5b137b48c0f56bd76b49169595a9f4a9467
    - name: loggregator-agent
      url: https://bosh.io/d/github.com/cloudfoundry/loggregator-agent-release?v=6.1.1
      version: 6.1.1
      sha1: c8f15cb137a5106cd83834721ee2709f37715930
    - name: log-cache
      url: https://bosh.io/d/github.com/cloudfoundry/log-cache-release?v=2.7.2
      version: 2.7.2
      sha1: 023aa7f9464f5175c144aa0a62014f8c360ce247
    - name: bosh-dns-aliases
      url: https://bosh.io/d/github.com/cloudfoundry/bosh-dns-aliases-release?v=0.0.3
      version: 0.0.3
      sha1: b0d0a0350ed87f1ded58b2ebb469acea0e026ccc
    - name: cf-cli
      url: https://bosh.io/d/github.com/bosh-packages/cf-cli-release?v=1.27.0
      version: 1.27.0
      sha1: 24da44758b6a0c9211cf3fed4afbfb3380a8d7be
    stemcells:
    - alias: default
      os: ubuntu-xenial
      version: "621.77"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: cf-deployment
  namespace: default
---
apiVersion: v1
data:
  charset.cnf: |-
    [client]
    default_character_set           = utf8

    [mysql]
    default_character_set           = utf8

    [mysqld]
    # Ignore the client information and use the default server character set.
    character_set_client_handshake  = false

    character_set_server            = utf8
    collation_server                = utf8_unicode_ci

    [mysqld_safe]
    default_character_set           = utf8
  node.cnf: |
    [mysqld]
    datadir=/var/lib/mysql
    default_storage_engine=InnoDB
    binlog_format=ROW
    innodb_flush_log_at_trx_commit  = 0
    innodb_flush_method             = O_DIRECT
    innodb_file_per_table           = 1
    innodb_autoinc_lock_mode=2
    bind_address = 0.0.0.0
    wsrep_slave_threads=2
    wsrep_cluster_address=gcomm://
    wsrep_provider=/usr/lib/galera3/libgalera_smm.so
    wsrep_sst_method=xtrabackup-v2
  ssl.cnf: |
    [mysqld]
    ssl-ca=/etc/mysql/tls/certs/ca
    ssl-cert=/etc/mysql/tls/certs/certificate
    ssl-key=/etc/mysql/tls/certs/private_key
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database-config-files
  namespace: default
---
apiVersion: v1
data:
  entrypoint.sh: |
    #!/bin/bash

    #    Copyright The Helm Authors.
    #
    #    Licensed under the Apache License, Version 2.0 (the "License");
    #    you may not use this file except in compliance with the License.
    #    You may obtain a copy of the License at
    #
    #        http://www.apache.org/licenses/LICENSE-2.0
    #
    #    Unless required by applicable law or agreed to in writing, software
    #    distributed under the License is distributed on an "AS IS" BASIS,
    #    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #    See the License for the specific language governing permissions and
    #    limitations under the License.
    #
    # This file was obtained from:
    # https://github.com/helm/charts/blob/7ccc9f99d7ab6b9554624985d9c9b9723b7253c0/stable/percona-xtradb-cluster/files/entrypoint.sh

    set -e

    if [[ -n "${DEBUG}" ]]; then
        set -x
    fi

    # shellcheck disable=SC1091
    . /startup-scripts/functions.sh

    ipaddr=$(hostname -i | awk ' { print $1 } ')
    hostname=$(hostname)
    echo "I AM $hostname - $ipaddr"

    # if command starts with an option, prepend mysqld
    if [ "${1:0:1}" = '-' ]; then
        CMDARG=( "$@" )
    fi

    cluster_join=$(resolveip -s "${K8S_SERVICE_NAME}" || echo "")
    if [[ -z "${cluster_join}" ]]; then
        echo "I am the Primary Node"
        init_mysql
        write_password_file
        exec mysqld --user=mysql --wsrep_cluster_name="$SHORT_CLUSTER_NAME" --wsrep_node_name="$hostname" \
        --wsrep_cluster_address=gcomm:// --wsrep_sst_method=xtrabackup-v2 \
        --wsrep_sst_auth="xtrabackup:$XTRABACKUP_PASSWORD" \
        --wsrep_node_address="$ipaddr" --pxc_strict_mode="$PXC_STRICT_MODE" "${CMDARG[@]}"
    else
        echo "I am not the Primary Node"
        chown -R mysql:mysql /var/lib/mysql || true # default is root:root 777
        touch /var/log/mysqld.log
        chown mysql:mysql /var/log/mysqld.log
        write_password_file
        exec mysqld --user=mysql --wsrep_cluster_name="$SHORT_CLUSTER_NAME" --wsrep_node_name="$hostname" \
        --wsrep_cluster_address="gcomm://$cluster_join" --wsrep_sst_method=xtrabackup-v2 \
        --wsrep_sst_auth="xtrabackup:$XTRABACKUP_PASSWORD" \
        --wsrep_node_address="$ipaddr" --pxc_strict_mode="$PXC_STRICT_MODE" "${CMDARG[@]}"
    fi
  functions.sh: |
    #!/bin/bash

    #    Copyright The Helm Authors.
    #
    #    Licensed under the Apache License, Version 2.0 (the "License");
    #    you may not use this file except in compliance with the License.
    #    You may obtain a copy of the License at
    #
    #        http://www.apache.org/licenses/LICENSE-2.0
    #
    #    Unless required by applicable law or agreed to in writing, software
    #    distributed under the License is distributed on an "AS IS" BASIS,
    #    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #    See the License for the specific language governing permissions and
    #    limitations under the License.
    #
    # This file was obtained from:
    # https://github.com/helm/charts/blob/7ccc9f99d7ab6b9554624985d9c9b9723b7253c0/stable/percona-xtradb-cluster/files/functions.sh

    write_password_file() {
        if [[ -n "${MYSQL_ROOT_PASSWORD}" ]]; then
            cat <<EOF > /root/.my.cnf
            [client]
            user=root
            password=${MYSQL_ROOT_PASSWORD}
    EOF
        fi
    }

    init_mysql() {
        SENTINEL=INIT_MYSQL_DONE
        DATADIR=/var/lib/mysql
        # if we have CLUSTER_JOIN - then we do not need to perform datadir initialize
        # the data will be copied from another node
        if [ ! -e "$DATADIR/$SENTINEL" ]; then
            echo "Removing pending files in $DATADIR, because sentinel was not reached"
            rm -rf "${DATADIR:?}"/*
            if [ -z "$MYSQL_ROOT_PASSWORD" ] && [ -z "$MYSQL_ALLOW_EMPTY_PASSWORD" ] && [ -z "$MYSQL_RANDOM_ROOT_PASSWORD" ] && [ -z "$MYSQL_ROOT_PASSWORD_FILE" ]; then
                echo >&2 'error: database is uninitialized and password option is not specified '
                echo >&2 '  You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ROOT_PASSWORD_FILE,  MYSQL_ALLOW_EMPTY_PASSWORD or MYSQL_RANDOM_ROOT_PASSWORD'
                exit 1
            fi

            if [ -n "$MYSQL_ROOT_PASSWORD_FILE" ] && [ -z "$MYSQL_ROOT_PASSWORD" ]; then
                MYSQL_ROOT_PASSWORD=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
            fi
            mkdir -p "$DATADIR"

            echo "Running --initialize-insecure on $DATADIR"
            ls -lah $DATADIR
            if [ "$PERCONA_MAJOR" = "5.6" ]; then
                mysql_install_db --user=mysql --datadir="$DATADIR"
            else
                mysqld --user=mysql --datadir="$DATADIR" --initialize-insecure
            fi
            chown -R mysql:mysql "$DATADIR" || true # default is root:root 777
            if [ -f /var/log/mysqld.log ]; then
                chown mysql:mysql /var/log/mysqld.log
            fi
            echo 'Finished --initialize-insecure'

            mysqld --user=mysql --datadir="$DATADIR" --skip-networking &
            pid="$!"

            mysql=( mysql "--protocol=socket" -uroot )

            for i in {30..0}; do
                if echo 'SELECT 1' | "${mysql[@]}" &> /dev/null; then
                    break
                fi
                echo 'MySQL init process in progress...'
                sleep 1
            done

            if [ "$i" = 0 ]; then
                echo >&2 'MySQL init process failed.'
                exit 1
            fi

            # sed is for https://bugs.mysql.com/bug.php?id=20545
            mysql_tzinfo_to_sql /usr/share/zoneinfo | sed 's/Local time zone must be set--see zic manual page/FCTY/' | "${mysql[@]}" mysql
            "${mysql[@]}" <<-EOSQL
            -- What's done in this file shouldn't be replicated
            --  or products like mysql-fabric won't work
            SET @@SESSION.SQL_LOG_BIN=0;
            CREATE USER 'root'@'${ALLOW_ROOT_FROM}' IDENTIFIED BY '${MYSQL_ROOT_PASSWORD}' ;
            GRANT ALL ON *.* TO 'root'@'${ALLOW_ROOT_FROM}' WITH GRANT OPTION ;
            GRANT ALL ON *.* TO 'root'@'localhost' WITH GRANT OPTION ;
            CREATE USER 'xtrabackup'@'localhost' IDENTIFIED BY '$XTRABACKUP_PASSWORD';
            GRANT RELOAD,PROCESS,LOCK TABLES,REPLICATION CLIENT ON *.* TO 'xtrabackup'@'localhost';
            GRANT REPLICATION CLIENT ON *.* TO monitor@'%' IDENTIFIED BY 'monitor';
            GRANT PROCESS ON *.* TO monitor@localhost IDENTIFIED BY 'monitor';
            CREATE USER 'mysql'@'localhost' IDENTIFIED BY '' ;
            DROP DATABASE IF EXISTS test ;
            FLUSH PRIVILEGES ;
    EOSQL

            if [ "$PERCONA_MAJOR" = "5.6" ]; then
                echo "SET PASSWORD FOR 'root'@'localhost' = PASSWORD('${MYSQL_ROOT_PASSWORD}'); FLUSH PRIVILEGES;" | "${mysql[@]}"
            else
                echo "ALTER USER 'root'@'localhost' IDENTIFIED BY '${MYSQL_ROOT_PASSWORD}'; FLUSH PRIVILEGES;" | "${mysql[@]}"
            fi

            if [ -n "$MYSQL_ROOT_PASSWORD" ]; then
                mysql+=( -p"${MYSQL_ROOT_PASSWORD}" )
            fi

            if [ "$MYSQL_DATABASE" ]; then
                echo "CREATE DATABASE IF NOT EXISTS \`$MYSQL_DATABASE\` ;" | "${mysql[@]}"
                mysql+=( "$MYSQL_DATABASE" )
            fi

            if [ "$MYSQL_USER" ] && [ "$MYSQL_PASSWORD" ]; then
                echo "CREATE USER '""$MYSQL_USER""'@'%' IDENTIFIED BY '""$MYSQL_PASSWORD""' ;" | "${mysql[@]}"

                if [ "$MYSQL_DATABASE" ]; then
                    echo "GRANT ALL ON \`""$MYSQL_DATABASE""\`.* TO '""$MYSQL_USER""'@'%' ;" | "${mysql[@]}"
                fi

                echo 'FLUSH PRIVILEGES ;' | "${mysql[@]}"
            fi

            if [ -n "$MYSQL_ONETIME_PASSWORD" ]; then
                "${mysql[@]}" <<-EOSQL
                ALTER USER 'root'@'%' PASSWORD EXPIRE;
    EOSQL
            fi
            if ! kill -s TERM "$pid" || ! wait "$pid"; then
                echo >&2 'MySQL init process failed.'
                exit 1
            fi

            echo
            echo 'MySQL init process done. Ready for start up.'
            echo
            touch "$DATADIR/$SENTINEL"
        fi
    }
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database-startup-scripts
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    - type: remove
      path: /instance_groups/name=scheduler/jobs/name=auctioneer
    - type: replace
      path: /instance_groups/name=scheduler:after
      value:
        name: auctioneer
        instances: 2
        stemcell: default
        update:
          serial: true
        jobs:
        -
          name: auctioneer
          release: diego
          properties:
            bpm:
              enabled: true
            diego:
              auctioneer:
                bbs:
                  ca_cert: "((diego_bbs_client.ca))"
                  client_cert: "((diego_bbs_client.certificate))"
                  client_key: "((diego_bbs_client.private_key))"
                ca_cert: "((diego_auctioneer_server.ca))"
                rep:
                  require_tls: true
                  ca_cert: "((diego_rep_client.ca))"
                  client_cert: "((diego_rep_client.certificate))"
                  client_key: "((diego_rep_client.private_key))"
                server_cert: "((diego_auctioneer_server.certificate))"
                server_key: "((diego_auctioneer_server.private_key))"
                skip_consul_lock: true
            enable_consul_service_registration: false
            loggregator:
              use_v2_api: true
              ca_cert: "((loggregator_tls_agent.ca))"
              cert: "((loggregator_tls_agent.certificate))"
              key: "((loggregator_tls_agent.private_key))"
            logging:
              format:
                timestamp: rfc3339
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-move-auctioneer
  namespace: default
---
apiVersion: v1
data:
  ops: "- type: remove\n  path: /instance_groups/name=doppler/jobs/name=log-cache\n-
    type: remove\n  path: /instance_groups/name=doppler/jobs/name=log-cache-gateway\n-
    type: remove\n  path: /instance_groups/name=doppler/jobs/name=log-cache-nozzle\n-
    type: remove\n  path: /instance_groups/name=doppler/jobs/name=log-cache-cf-auth-proxy\n-
    type: remove\n  path: /instance_groups/name=doppler/jobs/name=route_registrar\n-
    type: replace\n  path: /instance_groups/name=log-api:after\n  value:\n    name:
    log-cache\n    instances: 1\n    stemcell: default\n    update:\n      serial:
    false\n    jobs:\n    -\n      name: log-cache-cf-auth-proxy\n      properties:\n
    \       metrics:\n          ca_cert: \"((log_cache_cf_auth_proxy_metrics_tls.ca))\"\n
    \         cert: \"((log_cache_cf_auth_proxy_metrics_tls.certificate))\"\n          key:
    \"((log_cache_cf_auth_proxy_metrics_tls.private_key))\"\n          server_name:
    log_cache_cf_auth_proxy_metrics\n        cc:\n          ca_cert: \"((cc_tls.ca))\"\n
    \         common_name: cloud-controller-ng.service.cf.internal\n        proxy_ca_cert:
    \"((log_cache.ca))\"\n        proxy_port: 8083\n        external_cert: \"((logcache_ssl.certificate))\"\n
    \       external_key: \"((logcache_ssl.private_key))\"\n        uaa:\n          ca_cert:
    \"((uaa_ssl.ca))\"\n          client_id: doppler\n          client_secret: \"((uaa_clients_doppler_secret))\"\n
    \         internal_addr: https://uaa.service.cf.internal:8443\n      release:
    log-cache\n      \n    -\n      name: log-cache-gateway\n      properties:\n        gateway_addr:
    localhost:8081\n        proxy_cert: \"((log_cache_proxy_tls.certificate))\"\n
    \       proxy_key: \"((log_cache_proxy_tls.private_key))\"\n        metrics:\n
    \         ca_cert: \"((log_cache_gateway_metrics_tls.ca))\"\n          cert: \"((log_cache_gateway_metrics_tls.certificate))\"\n
    \         key: \"((log_cache_gateway_metrics_tls.private_key))\"\n          server_name:
    log_cache_gateway_metrics\n      release: log-cache\n      \n    -\n      name:
    log-cache\n      provides:\n        log-cache:\n          shared: true\n      properties:\n
    \       metrics:\n          ca_cert: \"((log_cache_metrics_tls.ca))\"\n          cert:
    \"((log_cache_metrics_tls.certificate))\"\n          key: \"((log_cache_metrics_tls.private_key))\"\n
    \         server_name: log_cache_metrics\n        health_addr: localhost:6060\n
    \       tls:\n          ca_cert: \"((log_cache.ca))\"\n          cert: \"((log_cache.certificate))\"\n
    \         key: \"((log_cache.private_key))\"\n      release: log-cache\n      \n
    \   -\n      consumes:\n        reverse_log_proxy:\n          from: reverse_log_proxy\n
    \     name: log-cache-nozzle\n      properties:\n        logs_provider:\n          tls:\n
    \           ca_cert: \"((logs_provider.ca))\"\n            cert: \"((logs_provider.certificate))\"\n
    \           key: \"((logs_provider.private_key))\"\n      release: log-cache\n
    \     \n    -\n      name: route_registrar\n      properties:\n        route_registrar:\n
    \         routes:\n          - name: log-cache-reverse-proxy\n            port:
    8083\n            tls_port: 8083\n            registration_interval: 20s\n            server_cert_domain_san:
    log-cache.((system_domain))\n            uris:\n            - log-cache.((system_domain))\n
    \           - \"*.log-cache.((system_domain))\"\n      release: routing"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-move-log-cache
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-move-routing-api
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-acceptance-tests
  namespace: default
---
apiVersion: v1
data:
  ops: "\n\n# These operations set the default values explicitly in order to get the
    rotate-cc-database-key\n# errand working. Without them, the rotate-cc-database-key
    errand is not able to resolve the CC BOSH\n# link correctly.\n- type: replace\n
    \ path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/max_connections?\n
    \ value: 25\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/pool_timeout?\n
    \ value: 10\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/ssl_verify_hostname?\n
    \ value: true\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/read_timeout?\n
    \ value: 3600\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/connection_validation_timeout?\n
    \ value: 3600\n- type: replace\n  path: /variables/-\n  value:\n    name: ccdb_key_label_encryption_key_0\n
    \   type: password\n\n# Set cc/database_encryption property in all CAPI jobs\n-
    type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/database_encryption\n
    \ value: {\"current_key_label\":\"encryption_key_0\",\"keys\":{\"encryption_key_0\":\"((ccdb_key_label_encryption_key_0))\"}}\n-
    type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/database_encryption\n
    \ value: {\"current_key_label\":\"encryption_key_0\",\"keys\":{\"encryption_key_0\":\"((ccdb_key_label_encryption_key_0))\"}}\n-
    type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/database_encryption\n
    \ value: {\"current_key_label\":\"encryption_key_0\",\"keys\":{\"encryption_key_0\":\"((ccdb_key_label_encryption_key_0))\"}}\n-
    type: replace\n  path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/database_encryption\n
    \ value: {\"current_key_label\":\"encryption_key_0\",\"keys\":{\"encryption_key_0\":\"((ccdb_key_label_encryption_key_0))\"}}\n\n#
    core_file_pattern should be disabled as CC is not running on a VM.\n- type: replace\n
    \ path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/core_file_pattern\n
    \ value: false\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/core_file_pattern\n
    \ value: false\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/core_file_pattern\n
    \ value: false\n- type: replace\n  path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/core_file_pattern\n
    \ value: false\n\n# Disable tuning /proc/sys kernel parameters as file_server
    is running on a container.\n- type: replace\n  path: /instance_groups/name=api/jobs/name=file_server/properties/set_kernel_parameters?\n
    \ value: false\n\n# We don't have a /var/vcap/job/*/packages directory, so we
    point to all the packages.\n- type: replace\n  path: /instance_groups/name=api/jobs/name=file_server/properties/diego?/file_server/static_directory\n
    \ value: \"/var/vcap/packages/\"\n\n# Enable volume services\n- type: replace\n
    \ path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/volume_services_enabled\n
    \ value: true\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/volume_services_enabled\n
    \ value: true\n- type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/volume_services_enabled\n
    \ value: true\n- type: replace\n  path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/volume_services_enabled\n
    \ value: true\n\n# Add quarks properties for cloud_controller_ng.\n- type: replace\n
    \ path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/quarks?\n
    \ value:\n    ports:\n    - name: api\n      protocol: TCP\n      internal: 9022\n
    \   - name: api-tls\n      protocol: TCP\n      internal: 9023\n    - name: api-mutual-tls\n
    \     protocol: TCP\n      internal: 9024\n    run:\n      healthcheck:\n        ccng_monit_http_healthcheck:\n
    \         readiness:\n            # This job exists just to healthcheck cloud_controller_ng;
    we're\n            # already doing that separately.\n            exec:\n              command:
    [/bin/true]\n          liveness:\n            exec:\n              command:\n
    \             - /usr/bin/pgrep\n              - --full\n              - --exact\n
    \             - bash /var/vcap/jobs/cloud_controller_ng/bin/ccng_monit_http_healthcheck\n
    \       cloud_controller_ng:\n          readiness: &cloud_controller_ng_readiness\n
    \           exec:\n              command:\n              - curl\n              -
    --fail\n              - --head\n              - --silent\n              - --unix-socket\n
    \             - /var/vcap/data/cloud_controller_ng/cloud_controller.sock\n              -
    http:/healthz\n          # We don't want a liveness probe here as we do migration
    here, and we\n          # do not want to interrupt that.  We may want to consider
    using a\n          # startupProbe in the future (once that feature stabilizes).\n
    \         liveness: ~\n        local_worker_1:\n          readiness: &cc_local_worker_readiness\n
    \           exec:\n              command: [/usr/bin/pgrep, --full, cc_api_worker]\n
    \       local_worker_2:\n          readiness: *cc_local_worker_readiness\n        nginx:\n
    \         readiness:\n            httpGet:\n              httpHeaders:\n              -
    name: Host\n                value: api\n              path: /healthz\n              port:
    9024\n              scheme: HTTPS\n          liveness:\n            exec:\n              command:
    [/usr/bin/pgrep, --full, \"nginx: master process\"]\n    post_start:\n      condition:\n
    \       exec:\n          command: [\"curl\", \"--fail\", \"--head\", \"--silent\",
    \"http://127.0.0.1:9022/healthz\"]\n\n# Add quarks properties for cc_uploader.\n-
    type: replace\n  path: /instance_groups/name=api/jobs/name=cc_uploader/properties/quarks?\n
    \ value:\n    ports:\n    - name: http\n      protocol: TCP\n      internal: 9090\n
    \   - name: https\n      protocol: TCP\n      internal: 9091\n    run:\n      healthcheck:\n
    \       cc_uploader:\n          readiness:\n            # cc-uploader does not
    have a health check endpoint; just use a TCP\n            # socket.\n            tcpSocket:\n
    \             port: 9091\n\n# Add quarks properties for file_server.\n- type:
    replace\n  path: /instance_groups/name=api/jobs/name=file_server/properties/quarks?\n
    \ value:\n    ports:\n    - name: file-server\n      protocol: TCP\n      internal:
    &file-server-port 8080\n    run:\n      healthcheck:\n        file_server:\n          readiness:\n
    \           httpGet:\n              path: /v1/static/file_server/bin/file-server\n
    \             port: *file-server-port\n\n# Add quarks properties for statsd_injector.\n-
    type: replace\n  path: /instance_groups/name=api/jobs/name=statsd_injector/properties/quarks?/run/healthcheck/statsd_injector/readiness/exec/command\n
    \ value:\n  - /bin/sh\n  - -c\n  - ss -nlu src localhost:8125 | grep :8125\n\n#
    Add quarks properties for policy-server.\n- type: replace\n  path: /instance_groups/name=api/jobs/name=policy-server/properties/quarks?\n
    \ value:\n    ports:\n    - name: policy-server\n      protocol: TCP\n      internal:
    4002\n    run:\n      healthcheck:\n        policy-server:\n          readiness:\n
    \           httpGet:\n              port: 4002\n              scheme: HTTPS\n
    \   post_start:\n      condition:\n        exec:\n          # policy-server doesn't
    support HTTP HEAD requests\n          command: [\"curl\", \"--insecure\", \"--fail\",
    \"--silent\", \"https://localhost:4002/\"]\n\n# Add quarks properties for policy-server-internal.\n-
    type: replace\n  path: /instance_groups/name=api/jobs/name=policy-server-internal/properties/quarks?\n
    \ value:\n    run:\n      healthcheck:\n        policy-server-internal:\n          readiness:
    &policy_server_internal_readiness\n            httpGet:\n              port: 31946\n
    \   post_start:\n      condition:\n        exec:\n          # policy-server-internal
    doesn't support HTTP HEAD requests\n          command: [\"curl\", \"--fail\",
    \"--silent\", \"http://localhost:31946/\"]\n\n- type: replace\n  path: /instance_groups/name=api/jobs/name=route_registrar/properties/quarks?/run/healthcheck/route_registrar\n
    \ value:\n    readiness: ~\n      # The route registrar doesn't expose anything
    to indicate if the\n      # routes are healthy\n\n- type: replace\n  path: /instance_groups/name=api/jobs/name=loggr-udp-forwarder/properties/quarks?/run/healthcheck/loggr-udp-forwarder/readiness/exec/command\n
    \ value: [\"sh\", \"-c\", \"ss -nlu sport = 3457 | grep :3457\"]\n- type: replace\n
    \ path: /instance_groups/name=api/jobs/name=cc_uploader/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/capi/cc_uploader/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Remove sysctl calls as we are running in containers.\n
    \   # cc_uploader_ctl in https://github.com/cloudfoundry/capi-release/blob/master/jobs/cc_uploader/templates/cc_uploader_ctl.erb#L26\n
    \   # also skips setting those parameters.\n    patch --verbose \"${target}\"
    <<'EOT'\n    @@ -6,6 +6,3 @@\n         /var/vcap/jobs/bosh-dns/bin/wait\n       fi\n
    \    fi\n    -\n    -sysctl -e -w net.ipv4.tcp_fin_timeout=10\n    -sysctl -e
    -w net.ipv4.tcp_tw_reuse=1\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n-
    type: replace\n  path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/quarks?/pre_render_scripts/bpm/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/capi/cloud_controller_ng/templates/bpm.yml.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Patch a few things on the BPM:\n    #   - DYNO
    environment variable is not needed.\n    #   - We don't enable New Relic.\n    #
    \  - NGINX maintenance shouldn't run.\n    patch --verbose \"${target}\" <<'EOT'\n
    \   @@ -20,7 +20,6 @@\n         \"BUNDLE_GEMFILE\" => \"/var/vcap/packages/cloud_controller_ng/cloud_controller_ng/Gemfile\",\n
    \        \"CLOUD_CONTROLLER_NG_CONFIG\" => \"/var/vcap/jobs/cloud_controller_ng/config/cloud_controller_ng.yml\",\n
    \        \"C_INCLUDE_PATH\" => \"/var/vcap/packages/libpq/include\",\n    -    \"DYNO\"
    => \"#{spec.job.name}-#{spec.index}\",\n         \"HOME\" => \"/home/vcap\",\n
    \        \"LANG\" => \"en_US.UTF-8\",\n         \"LIBRARY_PATH\" => \"/var/vcap/packages/libpq/lib\",\n
    \   @@ -79,8 +78,6 @@\n       \"processes\" => [\n         cloud_controller_ng_config,\n
    \        nginx_config,\n    -    nginx_newrelic_plugin_config,\n    -    nginx_maintenance_config,\n
    \        ccng_monit_http_healthcheck_config,\n       ]\n     }\n    EOT\n    \n
    \   sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-api
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-app-autoscaler
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add quarks properties for the auctioneer job.
    - type: replace
      path: /instance_groups/name=auctioneer/jobs/name=auctioneer/properties/quarks?
      value:
        ports:
        - name: auctioneer
          protocol: TCP
          internal: 9016
        activePassiveProbes:
          auctioneer-auctioneer:
            exec:
              command:
              - bash
              - -ce
              - "head -c0 </dev/tcp/${HOSTNAME}/9016"
    # Set the alias auctioneer.service.cf.internal instance group to auctioneer.
    - type: replace
      path: /addons/name=bosh-dns-aliases/jobs/name=bosh-dns-aliases/properties/aliases/domain=auctioneer.service.cf.internal/targets/0/instance_group
      value: auctioneer
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-auctioneer
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-brain-tests
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add quarks properties for cloud_controller_worker
    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker/properties/quarks?/run/healthcheck/worker_1
      value:
        readiness: &cloud_controller_worker_readiness
          exec:
            command: [/usr/bin/pgrep, --full, cc-worker-cloud_controller_worker]
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-cc-worker
  namespace: default
---
apiVersion: v1
data:
  ops: |2-


    # Remove directly from the cf-deployment.yml YAML file.
    - path: /addons/name=bosh-dns-aliases/jobs/name=bosh-dns-aliases/properties/aliases/domain=credhub.service.cf.internal?
      type: remove
    - path: /instance_groups/name=database/jobs/name=pxc-mysql/properties/seeded_databases/name=credhub?
      type: remove
    - path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa/clients/cc_service_key_client?
      type: remove
    - path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa/clients/credhub_admin_client?
      type: remove
    - path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/credhub_api?
      type: remove

    # XXX Is there a safer way to do edit the rep job property than to delete an array element by position?
    # XXX At least verify that trusted_ca_certificates[1] == "((credhub_tls.ca))" and fail if it doesn't?
    # XXX The current op could break silently during any cf-deployment upgrade that rearranges certs.
    - path: /instance_groups/name=diego-cell/jobs/name=rep/properties/containers/trusted_ca_certificates/1
      type: remove

    - path: /instance_groups/name=credhub?
      type: remove
    - path: /variables/name=credhub_encryption_password?
      type: remove
    - path: /variables/name=credhub_admin_client_secret?
      type: remove
    - path: /variables/name=credhub_database_password?
      type: remove
    - path: /variables/name=credhub_ca?
      type: remove
    - path: /variables/name=credhub_tls?
      type: remove
    - path: /releases/name=credhub?
      type: remove
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-credhub
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Remove database instance group and variables.
    - type: remove
      path: /instance_groups/name=database

    # Remove the PXC release and related variables.
    - type: remove
      path: /releases/name=pxc
    - type: remove
      path: /variables/name=pxc_galera_ca
    - type: remove
      path: /variables/name=pxc_server_ca
    - type: remove
      path: /variables/name=galera_server_certificate
    - type: remove
      path: /variables/name=mysql_server_certificate

    # Add certificates for PXC.
    - type: replace
      path: /variables/-
      value:
        name: pxc_ca
        type: certificate
        options:
          common_name: pxc_ca
          is_ca: true
    - type: replace
      path: /variables/-
      value:
        name: pxc_tls
        type: certificate
        options:
          ca: pxc_ca
          common_name: &pxc-cluster-address database.default

    # Override the address and CA cert with the one from PXC.
    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=bbs/properties/diego/bbs/sql/db_host?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=bbs/properties/diego/bbs/sql/ca_cert?
      value: &pxc-cluster-ca ((pxc_tls.ca))

    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=locket/properties/diego/locket/sql/db_host?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=locket/properties/diego/locket/sql/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaadb/address?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa?/ca_certs
      value:
      - *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/address?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/ccdb/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker/properties/ccdb/address?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker/properties/ccdb/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock/properties/ccdb/address?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock/properties/ccdb/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater/properties/ccdb/address?
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater/properties/ccdb/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=api/jobs/name=policy-server/properties/database/host
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=api/jobs/name=policy-server/properties/database/ca_cert?
      value: *pxc-cluster-ca

    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=silk-controller/properties/database/host
      value: *pxc-cluster-address
    - type: replace
      path: /instance_groups/name=diego-api/jobs/name=silk-controller/properties/database/ca_cert?
      value: *pxc-cluster-ca
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-database
  namespace: default
---
apiVersion: v1
data:
  ops: "# Override the addresses for the jobs under the diego-api instance group.\n-
    type: replace\n  path: /instance_groups/name=diego-api/jobs/name=bbs/properties/diego/bbs/locket?/api_location\n
    \ value: 127.0.0.1:8891\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=bbs/properties/diego/bbs/health_addr?\n
    \ value: 0.0.0.0:8890\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=cfdot/properties/bbs?/hostname\n
    \ value: 127.0.0.1\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=cfdot/properties/locket?/hostname\n
    \ value: 127.0.0.1\n- type: replace\n  path: /variables/name=diego_bbs_server/options?/alternative_names?/-\n
    \ value: '127.0.0.1'\n- type: replace\n  path: /variables/name=diego_locket_server/options?/alternative_names?/-\n
    \ value: '127.0.0.1'\n\n# Disable tuning /proc/sys kernel parameters as locket
    and bbs are running on containers.\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=locket/properties/set_kernel_parameters?\n
    \ value: false\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=bbs/properties/set_kernel_parameters?\n
    \ value: false\n\n# Add quarks properties for locket.\n- type: replace\n  path:
    /instance_groups/name=diego-api/jobs/name=locket/properties/quarks?\n  value:\n
    \   ports:\n    - name: locket\n      protocol: TCP\n      internal: 8891\n    run:\n
    \     healthcheck:\n        locket:\n          readiness:\n            exec:\n
    \             command:\n              - /var/vcap/packages/cfdot/bin/cfdot\n              -
    locks\n              - --locketAPILocation=localhost:8891\n              # We
    need to both give --skipCertVerify and provide a CA cert;\n              # skipping
    the former ends up with context deadline exceeded, and\n              # skipping
    the latter errors out failing to read file \"\"\n              - --skipCertVerify\n
    \             - --caCertFile=/var/vcap/jobs/locket/config/certs/ca.crt\n              -
    --clientCertFile=/var/vcap/jobs/locket/config/certs/server.crt\n              -
    --clientKeyFile=/var/vcap/jobs/locket/config/certs/server.key\n\n# Add quarks
    properties for bbs.\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=bbs/properties/quarks?\n
    \ value:\n    ports:\n    - name: cell-bbs-api\n      protocol: TCP\n      internal:
    8889 # If you change this values, change the probe below too\n    activePassiveProbes:\n
    \     bbs-bbs:\n        exec:\n          command:\n          - bash\n          -
    -ce\n          - \"head -c0 </dev/tcp/${HOSTNAME}/8889\"\n- type: replace\n  path:
    /instance_groups/name=diego-api/jobs/name=cfdot/properties/quarks?/bpm/processes\n
    \ value: []\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=bbs/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/diego/bbs/templates/bbs.json.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Advertise our spec address.\n    patch --verbose
    \"${target}\" <<'EOT'\n    62c62\n    <     \"#{scheme}://#{name.gsub('_', '-')}-#{spec.index}.#{base}:#{port}\"\n
    \   ---\n    >     \"#{scheme}://#{spec.address}:#{port}\"\n    EOT\n    \n    sha256sum
    \"${target}\" > \"${sentinel}\"\n\n- type: replace\n  path: /instance_groups/name=diego-api/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Place the cfdot related things into a location
    shared by all the jobs.\n    ##\n    # Implementation note: Given the small size
    of the pre-start script a\n    # patch is likely as large, or even larger than
    just the replacement\n    # script, we simply do the latter.\n    cat > \"${target}\"
    <<'EOT'\n    #!/bin/bash -e\n    \n    DEST=/var/vcap/data/cfdot/bin\n    mkdir
    -p \"${DEST}\"\n    \n    cp /var/vcap/jobs/cfdot/bin/setup     \"${DEST}/cfdot.sh\"\n
    \   cp /var/vcap/packages/cfdot/bin/cfdot \"${DEST}/cfdot\"\n    chown root:vcap
    \"${DEST}/cfdot.sh\"\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n-
    type: replace\n  path: /instance_groups/name=diego-api/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/setup.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Look for cfdot in the new, shared location.\n
    \   sed -i \"s|PATH=/var/vcap/packages|PATH=/var/vcap/data|g\" \"${target}\"\n
    \   \n    sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-diego-api
  namespace: default
---
apiVersion: v1
data:
  ops: "\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=vxlan-policy-agent/properties/disable?\n
    \ value: true\n\n# Enable BPM on garden.\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/bpm?/enabled\n
    \ value: true\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=rep/properties/set_kernel_parameters?\n
    \ value: false\n\n# Use a PVC for garden data\n# https://github.com/cloudfoundry-incubator/kubecf/issues/441\n-
    type: replace\n  path: /instance_groups/name=diego-cell/env?/bosh?/agent?/settings?/ephemeralAsPVC?\n
    \ value: true\n- type: replace\n  path: /instance_groups/name=diego-cell/vm_resources?/ephemeral_disk_size?\n
    \ value: 40960\n- type: remove\n  path: /instance_groups/name=diego-cell/persistent_disk_type?\n\n#
    Rep data should not be a PVC - since that could end up as a PVC\n# and if it's
    NFS, garden won't work\n- type: replace\n  path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/disks\n
    \ value:\n  - volume:\n      name: rep-data\n      emptyDir: {}\n    volumeMount:\n
    \     name: rep-data\n      mountPath: /var/vcap/data/rep\n    filters:\n      job_name:
    \"rep\"\n      process_name: \"rep\"\n  - volumeMount:\n      name: rep-data\n
    \     mountPath: /var/vcap/data/rep\n    filters:\n      job_name: \"garden\"\n
    \     process_name: \"garden\"\n  # An additional entry will be added for each
    stack-rootfs-setup job\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/garden/network_plugin?\n
    \ value: /var/vcap/data/runc-cni/bin/garden-external-networker\n\n- type: replace\n
    \ path: /instance_groups/name=diego-cell/jobs/name=garden-cni/properties/cni_plugin_dir?\n
    \ value: /var/vcap/data/silk-cni/bin\n\n- type: remove\n  path: /instance_groups/name=diego-cell/jobs/name=silk-cni/properties/dns_servers?\n\n#
    Add quarks properties for garden.\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/quarks?\n
    \ value:\n    run:\n      healthcheck:\n        garden:\n          readiness:\n
    \           exec:\n              command: [\"curl\", \"--head\", \"--fail\", \"--silent\",
    \"http://127.0.0.1:17019/debug/vars\"]\n    post_start:\n      condition:\n        exec:\n
    \         command: [sh, -c, 'ss -nlt sport = 17019 | grep \"LISTEN.*:17019\"']\n\n#
    Add quarks properties for route_emitter.\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=route_emitter/properties/quarks?\n
    \ value:\n    run:\n      healthcheck:\n        route_emitter:\n          readiness:
    &route_emitter_readiness\n            exec:\n              command: [\"curl\",
    \"--fail\", \"--silent\", \"http://127.0.0.1:17011/ping\"]\n    post_start:\n
    \     condition: *route_emitter_readiness\n\n# Add quarks properties for rep.\n-
    type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=rep/properties/quarks?\n
    \ value:\n    # Disable the ephemeral rep disk\n    bpm:\n      processes:\n      -
    name: rep\n        ephemeral_disk: false\n    ports:\n    - name: rep-tls\n      protocol:
    TCP\n      internal: 1801\n    run:\n      security_context:\n        capabilities:\n
    \         add:\n          - SYS_ADMIN\n      healthcheck:\n        rep:\n          readiness:\n
    \           exec:\n              command:\n              - curl\n              -
    --head\n              - --fail\n              - --insecure\n              - --cert\n
    \             - /var/vcap/jobs/rep/config/certs/tls.crt\n              - --key\n
    \             - /var/vcap/jobs/rep/config/certs/tls.key\n              - https://127.0.0.1:1800/ping\n
    \   post_start:\n      condition:\n        exec:\n          command: [sh, -c,
    'ss -nlt sport = 1800 | grep \"LISTEN.*:1800\"']\n\n# Set the unconfined AppArmor
    profile for bpm-pre-start-rep in order to perform mounts.\n# This works in combination
    with CAP_SYS_ADMIN Linux capability.\n- type: replace\n  path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/annotations/container.apparmor.security.beta.kubernetes.io~1bpm-pre-start-rep\n
    \ value: unconfined\n\n# Set the unconfined AppArmor profile for rep-rep in order
    to perform mounts.\n# This works in combination with CAP_SYS_ADMIN Linux capability.\n-
    type: replace\n  path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/annotations/container.apparmor.security.beta.kubernetes.io~1rep-rep\n
    \ value: unconfined\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=cfdot/properties/quarks?/bpm/processes\n
    \ value: []\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden-cni/properties/quarks?/bpm/processes\n
    \ value: []\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=silk-cni/properties/quarks?/bpm/processes\n
    \ value: []\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/garden/network_pool?\n
    \ value: 10.38.0.0/16\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/garden/apparmor_profile?\n
    \ value: \"\"\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties/garden/cleanup_process_dirs_on_wait\n
    \ value: false\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=garden/properties?/garden?/disable_swap_limit?\n
    \ value: true\n\n# To support multi-clusters and deploy a cell\n- type: replace\n
    \ path: /instance_groups/name=diego-cell/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Place the cfdot related things into a location
    shared by all the jobs.\n    ##\n    # Implementation note: Given the small size
    of the pre-start script a\n    # patch is likely as large, or even larger than
    just the replacement\n    # script, we simply do the latter.\n    cat > \"${target}\"
    <<'EOT'\n    #!/bin/bash -e\n    \n    DEST=/var/vcap/data/cfdot/bin\n    mkdir
    -p \"${DEST}\"\n    \n    cp /var/vcap/jobs/cfdot/bin/setup     \"${DEST}/cfdot.sh\"\n
    \   cp /var/vcap/packages/cfdot/bin/cfdot \"${DEST}/cfdot\"\n    chown root:vcap
    \"${DEST}/cfdot.sh\"\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n-
    type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/setup.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Look for cfdot in the new, shared location.\n
    \   sed -i \"s|PATH=/var/vcap/packages|PATH=/var/vcap/data|g\" \"${target}\"\n
    \   \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n- type: replace\n  path:
    /instance_groups/name=diego-cell/jobs/name=garden-cni/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/cf-networking/garden-cni/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Place the garden-external-networker into a
    location shared by all the jobs.\n    patch --verbose \"${target}\" <<'EOT'\n
    \   @@ -1,3 +1,8 @@\n     #!/bin/bash -eu\n    \n     rm -rf /var/vcap/data/garden-cni
    || true\n    +\n    +DEST=/var/vcap/data/runc-cni/bin/\n    +\n    +mkdir -p \"${DEST}\"\n
    \   +cp /var/vcap/packages/runc-cni/bin/garden-external-networker \"${DEST}/garden-external-networker\"\n
    \   EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n- type: replace\n
    \ path: /instance_groups/name=diego-cell/jobs/name=garden/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/garden-runc/garden/templates/bin/bpm-pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Patch the pre-start script to setup /var/vcap/data\n
    \   patch --verbose \"${target}\" <<'EOT'\n    2a3,4\n    > find /var/vcap/data/grootfs/
    -iname '*' -delete\n    > \n    20a23,25\n    > \n    > # Ensure that runc and
    container processes can stat everything\n    > chmod ugo+rx /var/vcap/data/grootfs\n
    \   EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n- type: replace\n
    \ path: /instance_groups/name=diego-cell/jobs/name=rep/properties/quarks?/pre_render_scripts/bpm/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/diego/rep/templates/bpm.yml.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Patch BPM, since we're actually running in-cluster
    without BPM\n    patch --verbose \"${target}\" <<'EOT'\n    @@ -6,7 +6,7 @@\n
    \        open_files: 100000\n       hooks:\n         pre_start: /var/vcap/jobs/rep/bin/bpm-pre-start\n
    \   -  ephemeral_disk: true\n    +  ephemeral_disk: false\n       additional_volumes:\n
    \        - path: <%= p(\"diego.executor.volman.driver_paths\") %>\n         -
    path : /var/vcap/data/garden\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n-
    type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=rep/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/diego/rep/templates/bpm-pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Use the ephemeral data directory for the rootfs.\n
    \   patch --verbose \"${target}\" <<'EOT'\n    @@ -5,3 +5,7 @@\n     $bin_dir/set-rep-kernel-params\n
    \   \n     $bin_dir/setup_mounted_data_dirs\n    +\n    +mkdir -p /var/vcap/data/shared-packages/\n
    \   +cp -r /var/vcap/packages/healthcheck /var/vcap/data/shared-packages/\n    +cp
    -r /var/vcap/packages/proxy /var/vcap/data/shared-packages/\n    EOT\n    \n    sha256sum
    \"${target}\" > \"${sentinel}\"\n\n- type: replace\n  path: /instance_groups/name=diego-cell/jobs/name=rep/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/diego/rep/templates/rep.json.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Don't share /var/vcap/packages between containers.\n
    \   patch --verbose \"${target}\" <<'EOT'\n    @@ -39,7 +39,7 @@\n         disk_mb:
    p(\"diego.executor.disk_capacity_mb\").to_s,\n         enable_consul_service_registration:
    p(\"enable_consul_service_registration\"),\n         enable_declarative_healthcheck:
    p(\"enable_declarative_healthcheck\"),\n    -    declarative_healthcheck_path:
    \"/var/vcap/packages/healthcheck\",\n    +    declarative_healthcheck_path: \"/var/vcap/data/shared-packages/healthcheck\",\n
    \        enable_container_proxy: p(\"containers.proxy.enabled\"),\n         container_proxy_require_and_verify_client_certs:
    p(\"containers.proxy.require_and_verify_client_certificates\"),\n         container_proxy_trusted_ca_certs:
    p(\"containers.proxy.trusted_ca_certificates\"),\n    @@ -47,7 +47,7 @@\n         container_proxy_ads_addresses:
    p(\"containers.proxy.ads_addresses\"),\n         enable_unproxied_port_mappings:
    p(\"containers.proxy.enable_unproxied_port_mappings\"),\n         proxy_memory_allocation_mb:
    p(\"containers.proxy.additional_memory_allocation_mb\"),\n    -    container_proxy_path:
    \"/var/vcap/packages/proxy\",\n    +    container_proxy_path: \"/var/vcap/data/shared-packages/proxy\",\n
    \        container_proxy_config_path: \"/var/vcap/data/rep/shared/garden/proxy_config\",\n
    \        evacuation_polling_interval: \"#{p(\"diego.rep.evacuation_polling_interval_in_seconds\")}s\",\n
    \        evacuation_timeout: \"#{p(\"diego.rep.evacuation_timeout_in_seconds\")}s\",\n
    \   EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n- type: replace\n
    \ path: /instance_groups/name=diego-cell/jobs/name=silk-cni/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/silk/silk-cni/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Place the silk-cni related things into a location
    shared by all the jobs.\n    patch --verbose \"${target}\" <<'EOT'\n    @@ -4,3
    +4,8 @@\n     /var/vcap/packages/silk-cni/bin/cni-teardown \\\n       --config
    /var/vcap/jobs/silk-cni/config/teardown-config.json\n     <% end %>\n    +\n    +DEST=/var/vcap/data/silk-cni/bin\n
    \   +\n    +mkdir -p \"${DEST}\"\n    +cp /var/vcap/packages/silk-cni/bin/* \"${DEST}/\"\n
    \   EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-diego-cell
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add quarks properties for doppler.
    - type: replace
      path: /instance_groups/name=doppler/jobs/name=doppler/properties/quarks?
      value:
        ports:
        - name: doppler-grpc
          protocol: TCP
          internal: 8082
        run:
          healthcheck:
            doppler:
              readiness:
                exec:
                  command: [sh, -c, 'ss -nlt sport = 8082 | grep "LISTEN.*:8082"']
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-doppler
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-eirini-helm
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add quarks properties for loggregator_trafficcontroller.
    - type: replace
      path: /instance_groups/name=log-api/jobs/name=loggregator_trafficcontroller/properties/quarks?
      value:
        envs:
        - name: TRAFFIC_CONTROLLER_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        run:
          healthcheck:
            loggregator_trafficcontroller:
              # The traffic controller doesn't expose anything to indicate its healthiness.
              readiness: ~

    # Add quarks properties for reverse_log_proxy.
    - type: replace
      path: /instance_groups/name=log-api/jobs/name=reverse_log_proxy/properties/reverse_log_proxy?/pprof/port
      value: "33047"
    - type: replace
      path: /instance_groups/name=log-api/jobs/name=reverse_log_proxy/properties/quarks?
      value:
        ports:
        - name: grpc-egress
          protocol: TCP
          internal: 8082
        run:
          healthcheck:
            reverse_log_proxy:
              readiness:
                exec:
                  command:
                  - curl
                  - --fail
                  - --head
                  - --silent
                  - http://localhost:33047/debug/pprof/cmdline

    - type: replace
      path: /instance_groups/name=log-api/jobs/name=reverse_log_proxy_gateway/properties/quarks?/bpm/processes/name=reverse_log_proxy_gateway/env/PPROF_PORT?
      value: "33045"
    - type: replace
      path: /instance_groups/name=log-api/jobs/name=reverse_log_proxy_gateway/properties/quarks?/run/healthcheck/reverse_log_proxy_gateway/readiness/exec/command
      value: ["curl", "--fail", "--head", "--silent", "http://localhost:33045/debug/pprof/cmdline"]

    - type: replace
      path: /instance_groups/name=log-api/jobs/name=route_registrar/properties/quarks?/run/healthcheck/route_registrar
      value:
        # The route registrar doesn't expose anything to indicate if the
        # routes are healthy.
        readiness: ~
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-log-api
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Change the log_cache_ca CN to avoid clashing with the other log-cache certificate CNs.
    - type: replace
      path: /variables/name=log_cache_ca/options/common_name
      value: log-cache-ca

    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=log-cache/properties/health_addr?
      value: "::6060"

    # Add quarks properties for log-cache.
    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=log-cache/properties/quarks?
      value:
        ports:
        - name: log-cache-metrics
          protocol: TCP
          internal: 6060
        - name: log-cache
          protocol: TCP
          internal: 8080
        run:
          healthcheck:
            log-cache:
              readiness:
                exec:
                  command:
                  - curl
                  - --insecure
                  - --fail
                  - --head
                  - --silent
                  - --cert
                  - /var/vcap/jobs/log-cache/config/certs/metrics.crt
                  - --key
                  - /var/vcap/jobs/log-cache/config/certs/metrics.key
                  - https://localhost:6060/debug/pprof/cmdline

    # Add quarks properties for log-cache-gateway.
    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=log-cache-gateway/properties/quarks?
      value:
        ports:
        - name: log-cache-gateway-metrics
          protocol: TCP
          internal: 6063
        run:
          healthcheck:
            log-cache-gateway:
              readiness:
                # Unfortunately, by default the health port listens on localhost only
                # and isn't easily configurable.
                exec:
                  command:
                  - curl
                  - --insecure
                  - --fail
                  - --head
                  - --silent
                  - --cert
                  - /var/vcap/jobs/log-cache/config/certs/metrics.crt
                  - --key
                  - /var/vcap/jobs/log-cache/config/certs/metrics.key
                  - https://localhost:6063/debug/pprof/cmdline

    # Add quarks properties for log-cache-nozzle.
    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=log-cache-nozzle/properties/quarks?
      value:
        run:
          healthcheck:
            log-cache-nozzle:
              readiness:
                # Unfortunately, by default the health port listens on localhost only
                # and isn't easily configurable.
                exec:
                  command: [curl, --fail, --head, --silent, http://localhost:6061/debug/pprof/cmdline]

    # Add quarks properties for log-cache-cf-auth-proxy.
    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=log-cache-cf-auth-proxy/properties/quarks?
      value:
        ports:
        - name: log-cache-cf-auth-proxy-metrics
          protocol: TCP
          internal: 6065
        - name: log-cache-cf-auth-proxy
          protocol: TCP
          internal: 8083
        run:
          healthcheck:
            log-cache-cf-auth-proxy:
              readiness:
                # Unfortunately, by default the health port listens on localhost only
                # and isn't easily configurable.
                exec:
                  command:
                  - curl
                  - --insecure
                  - --fail
                  - --head
                  - --silent
                  - --cert
                  - /var/vcap/jobs/log-cache/config/certs/metrics.crt
                  - --key
                  - /var/vcap/jobs/log-cache/config/certs/metrics.key
                  - https://localhost:6065/debug/pprof/cmdline

    # Add quarks properties for route_registrar.
    - type: replace
      path: /instance_groups/name=log-cache/jobs/name=route_registrar/properties/quarks?
      value:
        run:
          healthcheck:
            route_registrar:
              # The route registrar doesn't expose anything to indicate if the
              # routes are healthy.
              readiness: ~

    # Add log-cache.service.cf.internal DNS alias to be able to point CC to it.
    - type: replace
      path: /addons/name=bosh-dns-aliases/jobs/name=bosh-dns-aliases/properties/aliases/-
      value:
        domain: log-cache.service.cf.internal
        targets:
        - deployment: cf
          domain: bosh
          instance_group: log-cache
          network: default
          query: '*'

    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties?/cc/logcache/host
      value: log-cache.service.cf.internal
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-log-cache
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add the nats BOSH DNS alias.
    - type: replace
      path: /addons/name=bosh-dns-aliases/jobs/name=bosh-dns-aliases/properties/aliases/-
      value:
        domain: nats.service.cf.internal
        targets:
        - deployment: cf
          domain: bosh
          instance_group: nats
          network: default
          query: '*'

    # Add quarks properties.
    - type: replace
      path: /instance_groups/name=nats/jobs/name=nats/properties/quarks?
      value:
        ports:
        - name: nats
          protocol: TCP
          internal: 4222
        - name: nats-routes
          protocol: TCP
          internal: 4223
        - name: nats-tls
          protocol: TCP
          internal: 4224
        - name: nats-tls-routes
          protocol: TCP
          internal: 4225
        run:
          healthcheck:
            nats:
              readiness:
                exec:
                  command:
                  - sh
                  - -c
                  - ss -nlt sport = 4222 | grep "LISTEN.*:4222" && ss -nlt sport = 4223 | grep "LISTEN.*:4223"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-nats
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # Add quarks properties for the gorouter job.
    - type: replace
      path: /instance_groups/name=router/jobs/name=gorouter/properties/quarks?
      value:
        ports:
        - name: router
          protocol: TCP
          internal: 80
        - name: router-ssl
          protocol: TCP
          internal: 443
        run:
          healthcheck:
            gorouter:
              readiness:
                httpGet:
                  port: 8080
                  path: /health
        post_start:
          condition:
            exec:
              command: ["curl", "--fail", "--head", "http://127.0.0.1:8080/health"]

    # Disable tuning /proc/sys kernel parameters as things are running on a container.
    - type: replace
      path: /instance_groups/name=router/jobs/name=gorouter/properties/router?/set_kernel_parameters
      value: false

    - type: replace
      path: /instance_groups/name=router/jobs/name=loggr-udp-forwarder/properties/quarks?/run/healthcheck/loggr-udp-forwarder
      value:
        readiness:
          exec:
            command: ["sh", "-c", "ss -nlu sport = 3457 | grep :3457"]

    # Add necessary labels to the router instance group so that the service can select it to create the
    # endpoint.
    - type: replace
      path: /instance_groups/name=router/env?/bosh/agent/settings/labels/app.kubernetes.io~1component
      value: "router"
    - type: replace
      path: /instance_groups/name=router/env?/bosh/agent/settings/labels/app.kubernetes.io~1instance
      value: "kubecf"
    - type: replace
      path: /instance_groups/name=router/env?/bosh/agent/settings/labels/app.kubernetes.io~1version
      value: "2.4.0"

    # Update cipher suites based on https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations
    - type: replace
      path: /instance_groups/name=router/jobs/name=gorouter/properties/router/cipher_suites?
      value: "\
        ECDHE-ECDSA-CHACHA20-POLY1305:\
        ECDHE-RSA-CHACHA20-POLY1305:\
        ECDHE-ECDSA-AES128-GCM-SHA256:\
        ECDHE-RSA-AES128-GCM-SHA256:\
        ECDHE-ECDSA-AES256-GCM-SHA384:\
        ECDHE-RSA-AES256-GCM-SHA384:\
        AES128-GCM-SHA256:\
        AES256-GCM-SHA384"

    # Trust the diego_instance_identity_ca certificate - trusting its CA
    # is insufficient with the cf-operator
    # Also add the CredHub CA
    - type: replace
      path: /instance_groups/name=router/jobs/name=gorouter/properties/router/ca_certs
      value: |
        ((diego_instance_identity_ca.ca))
        ((cc_tls.ca))
        ((uaa_ssl.ca))
        ((network_policy_server_external.ca))

    # If the router certificate is provided via Helm, don't generate the router_ca and router_ssl
    # certificates. router_ssl becomes an implicit variable.
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-router
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    # Disable routing-api.
    - type: remove
      path: /instance_groups/name=api/jobs/name=routing-api

    - type: remove
      path: /instance_groups/name=database?/jobs/name=pxc-mysql/properties/seeded_databases/name=routing-api

    - type: replace
      path: /instance_groups/name=router/jobs/name=gorouter/properties/routing_api/enabled
      value: false

    - type: remove
      path: /addons/name=bosh-dns-aliases/jobs/name=bosh-dns-aliases/properties/aliases/domain=routing-api.service.cf.internal

    - type: remove
      path: /variables/name=routing_api_tls

    - type: remove
      path: /variables/name=routing_api_tls_client
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-routing-api
  namespace: default
---
apiVersion: v1
data:
  ops: "- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock/properties/quarks?/run/healthcheck/cloud_controller_clock\n
    \ value:\n    readiness:\n      # There is no good readiness check for the scheduled
    tasks\n      exec:\n        command: [\"pgrep\", \"--full\", \"clock:start\"]\n\n-
    type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater/properties/quarks?/run/healthcheck/cc_deployment_updater\n
    \ value:\n    readiness:\n      exec:\n        command:\n        # We should sleep
    about once every 5 seconds; check that the last entry was no more than 2 cycles
    ago\n        - /bin/sh\n        - -c\n        - >\n          tac /var/vcap/sys/log/cc_deployment_updater/cc_deployment_updater.log\n
    \         | grep --max-count=1 Sleeping\n          | jq -e '.timestamp | gsub(\".[0-9]+Z$\";
    \"Z\") | fromdate | now - . | . < 10'\n    liveness:\n      exec:\n        command:
    [\"pgrep\", \"--full\", \"deployment_updater:start\"]\n\n- type: replace\n  path:
    /instance_groups/name=scheduler/jobs/name=statsd_injector/properties/quarks?/run/healthcheck/statsd_injector/readiness/exec/command\n
    \ value: [\"/bin/sh\", \"-c\", \"ss -nlu src localhost:8125 | grep :8125\"]\n\n-
    type: replace\n  path: /instance_groups/name=scheduler/jobs/name=tps/properties/quarks?/run/healthcheck/watcher/readiness/exec/command\n
    \ value: [\"curl\", \"--fail\", \"--silent\", \"http://127.0.0.1:17015/debug/pprof/cmdline\"]\n\n#
    Add quarks properties for the ssh_proxy job.\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=ssh_proxy/properties/diego/ssh_proxy/disable_healthcheck_server\n
    \ value: false\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=ssh_proxy/properties/quarks?\n
    \ value:\n    ports:\n    - name: ssh-proxy\n      protocol: TCP\n      internal:
    2222\n    run:\n      healthcheck:\n        ssh_proxy:\n          readiness:\n
    \           httpGet:\n              port: 2223\n\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=service-discovery-controller/properties/quarks?/run/healthcheck/service-discovery-controller\n
    \ value:\n    readiness:\n      # Proper connection requires a TLS client cert;
    that's not worth it right now.\n      tcpSocket:\n        port: 8054\n\n# Add
    necessary labels to the scheduler instance group so that the service can select
    it to create\n# the endpoint.\n- type: replace\n  path: /instance_groups/name=scheduler/env?/bosh/agent/settings/labels/app.kubernetes.io~1component\n
    \ value: \"ssh-proxy\"\n- type: replace\n  path: /instance_groups/name=scheduler/env?/bosh/agent/settings/labels/app.kubernetes.io~1instance\n
    \ value: \"kubecf\"\n- type: replace\n  path: /instance_groups/name=scheduler/env?/bosh/agent/settings/labels/app.kubernetes.io~1version\n
    \ value: \"2.4.0\"\n\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cfdot/properties/quarks?/bpm/processes\n
    \ value: []\n- type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Place the cfdot related things into a location
    shared by all the jobs.\n    ##\n    # Implementation note: Given the small size
    of the pre-start script a\n    # patch is likely as large, or even larger than
    just the replacement\n    # script, we simply do the latter.\n    cat > \"${target}\"
    <<'EOT'\n    #!/bin/bash -e\n    \n    DEST=/var/vcap/data/cfdot/bin\n    mkdir
    -p \"${DEST}\"\n    \n    cp /var/vcap/jobs/cfdot/bin/setup     \"${DEST}/cfdot.sh\"\n
    \   cp /var/vcap/packages/cfdot/bin/cfdot \"${DEST}/cfdot\"\n    chown root:vcap
    \"${DEST}/cfdot.sh\"\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\"\n\n-
    type: replace\n  path: /instance_groups/name=scheduler/jobs/name=cfdot/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    ##\n    # ATTENTION: This is part of
    a set of six interconnected patches.\n    #            Two files spread over three
    instance groups.\n    # See\n    # - bosh/releases/pre_render_scripts/diego-cell/cfdot/jobs\n
    \   # - bosh/releases/pre_render_scripts/diego-api/cfdot/jobs\n    # - bosh/releases/pre_render_scripts/scheduler/cfdot/jobs\n
    \   \n    set -o errexit -o nounset\n    \n    target=\"/var/vcap/all-releases/jobs-src/diego/cfdot/templates/setup.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Look for cfdot in the new, shared location.\n
    \   sed -i \"s|PATH=/var/vcap/packages|PATH=/var/vcap/data|g\" \"${target}\"\n
    \   \n    sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-scheduler
  namespace: default
---
apiVersion: v1
data:
  ops: "\n- type: replace\n  path: /instance_groups/name=singleton-blobstore/persistent_disk?\n
    \ value: 102400 # 100GB\n- type: remove\n  path: /instance_groups/name=singleton-blobstore/persistent_disk_type\n\n-
    type: replace\n  path: /instance_groups/name=singleton-blobstore/jobs/name=blobstore/properties/blobstore/internal_access_rules?\n
    \ value: [ \"allow 10.0.0.0/8;\",\"allow 172.16.0.0/12;\", \"allow 192.168.0.0/16;\"
    , \"allow 100.64.0.0/10;\"]\n- type: replace\n  path: /instance_groups/name=singleton-blobstore/jobs/name=blobstore/properties/quarks?\n
    \ value:\n    ports:\n    - name: http\n      protocol: TCP\n      internal: 8080\n
    \   - name: https\n      protocol: TCP\n      internal: 4443\n    run:\n      security_context:\n
    \       runAsUser: 1000 # vcap\n      healthcheck:\n        nginx:\n          readiness:\n
    \           tcpSocket:\n              port: 8080\n          liveness:\n            exec:\n
    \             command: [pgrep, --full, 'nginx: master process']\n        url_signer:\n
    \         readiness:\n            exec:\n              command: [test, -S, /var/vcap/data/blobstore/signer.sock]\n\n-
    type: replace\n  path: /instance_groups/name=singleton-blobstore/jobs/name=route_registrar/properties/quarks?/run/healthcheck/route_registrar\n
    \ value:\n    readiness: ~\n      # The route registrar doesn't expose anything
    to indicate if the\n      # routes are healthy.\n- type: replace\n  path: /instance_groups/name=singleton-blobstore/jobs/name=blobstore/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   # Remove /var/vcap/packages from chowing.\n    \n    target=\"/var/vcap/all-releases/jobs-src/capi/blobstore/templates/pre-start.sh.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    patch --verbose \"${target}\" <<'EOT'\n    @@
    -9,7 +9,6 @@\n       local data_dir=/var/vcap/data/blobstore\n       local store_tmp_dir=$store_dir/tmp/uploads\n
    \      local data_tmp_dir=$data_dir/tmp/uploads\n    -  local nginx_webdav_dir=/var/vcap/packages/nginx_webdav\n
    \   \n       mkdir -p $run_dir\n       mkdir -p $log_dir\n    @@ -19,7 +18,7 @@\n
    \      mkdir -p $data_tmp_dir\n    \n       chown vcap:vcap $store_dir\n    -
    \ local dirs=\"$run_dir $log_dir $store_tmp_dir $data_dir $data_tmp_dir $nginx_webdav_dir
    ${nginx_webdav_dir}/..\"\n    +  local dirs=\"$run_dir $log_dir $store_tmp_dir
    $data_dir $data_tmp_dir\"\n       local num_needing_chown=$(find $dirs -not -user
    vcap -or -not -group vcap | wc -l)\n    \n       if [ $num_needing_chown -gt 0
    ]; then\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-singleton-blobstore
  namespace: default
---
apiVersion: v1
data:
  ops: |2-


    - type: remove
      path: /instance_groups/name=smoke-tests
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-smoke-tests
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # SITS only makes sense when using Diego, for this reason, we only enable it if Eirini is not
    # enabled.
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-sync-integration-tests
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    # Disable the tcp-router ig, as there will be no routing-api SSE events to read from.
    - type: remove
      path: /instance_groups/name=tcp-router

    - type: remove
      path: /variables/name=uaa_clients_tcp_router_secret

    - type: remove
      path: /instance_groups/name=uaa/jobs/name=uaa/properties/uaa/clients/tcp_router
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-tcp-router
  namespace: default
---
apiVersion: v1
data:
  ops: "# Add quarks properties.\n- type: replace\n  path: /instance_groups/name=uaa/jobs/name=uaa/properties/quarks?\n
    \ value:\n    ports:\n    - name: http\n      protocol: TCP\n      internal: 8080\n
    \   - name: https\n      protocol: TCP\n      internal: &uaa_https_port 8443\n
    \   run:\n      healthcheck:\n        uaa:\n          # UAA has a long period
    of cert import, so we can't set up a liveness\n          # check without killing
    it accidentally.\n          readiness: &uaa_readiness\n            exec:\n              command:
    ['sh', '-c', '/var/vcap/jobs/uaa/bin/health_check']\n    post_start:\n      condition:
    *uaa_readiness\n\n- type: replace\n  path: /instance_groups/name=uaa/jobs/name=route_registrar/properties/quarks?/run/healthcheck/route_registrar\n
    \ value:\n    readiness: ~\n      # The route registrar doesn't expose anything
    to indicate if the\n      # routes are healthy.\n\n- type: replace\n  path: /instance_groups/name=uaa/jobs/name=statsd_injector/properties/quarks?/run/healthcheck/statsd_injector/readiness/exec/command\n
    \ value: [\"/bin/sh\", \"-c\", \"ss -nlu src localhost:8125 | grep :8125\"]\n-
    type: replace\n  path: /instance_groups/name=uaa/jobs/name=uaa/properties/quarks?/pre_render_scripts/jobs/-\n
    \ value: |\n    #!/usr/bin/env bash\n    \n    set -o errexit -o nounset\n    \n
    \   target=\"/var/vcap/all-releases/jobs-src/uaa/uaa/templates/bin/pre-start.erb\"\n
    \   sentinel=\"${target}.patch_sentinel\"\n    if [[ -f \"${sentinel}\" ]]; then\n
    \     if sha256sum --check \"${sentinel}\" ; then\n        echo \"Patch already
    applied. Skipping\"\n        exit 0\n      fi\n      echo \"Sentinel mismatch,
    re-patching\"\n    fi\n    \n    # Patch bin/pre-start.erb for the certificates
    to work with SUSE.\n    patch --verbose \"${target}\" <<'EOT'\n    --- pre-start.erb
    \ 2019-12-04 08:37:51.046503943 +0100\n    +++ - 2019-12-04 08:41:36.055142488
    +0100\n    @@ -32,9 +32,24 @@\n         <% end %>\n    \n         log \"Trying
    to run update-ca-certificates...\"\n    -    # --certbundle is an undocumented
    flag in the update-ca-certificates script\n    -    # https://salsa.debian.org/debian/ca-certificates/blob/master/sbin/update-ca-certificates#L53\n
    \   -    timeout --signal=KILL 180s /usr/sbin/update-ca-certificates -f -v --certbundle
    \"$(basename \"${OS_CERTS_FILE}\")\"\n    +    source /etc/os-release\n    +    case
    \"${ID}\" in\n    +      *ubuntu*)\n    +        # --certbundle is an undocumented
    flag in the update-ca-certificates script\n    +        # https://salsa.debian.org/debian/ca-certificates/blob/master/sbin/update-ca-certificates#L53\n
    \   +        timeout --signal=KILL 180s /usr/sbin/update-ca-certificates -f -v
    --certbundle \"$(basename \"${OS_CERTS_FILE}\")\"\n    +      ;;\n    +\n    +
    \     *suse|sles*)\n    +        timeout --signal=KILL 180s /usr/sbin/update-ca-certificates
    -f -v\n    +        mv /var/lib/ca-certificates/ca-bundle.pem /etc/ssl/certs/\"$(basename
    \"${OS_CERTS_FILE}\")\"\n    +      ;;\n    +\n    +      *)\n    +        echo
    \"Unsupported operating system: ${PRETTY_NAME}\"\n    +        exit 42\n    +
    \     ;;\n    +    esac\n     }\n    \n     function new_cache_files_are_identical
    {\n    EOT\n    \n    sha256sum \"${target}\" > \"${sentinel}\""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-uaa
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    - type: remove
      path: /addons/name=bpm

    - type: replace
      path: /addons/name=loggregator_agent/jobs/name=loggregator_agent/properties/quarks?/envs?
      value:
      - name: AGENT_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: AGENT_INDEX
        value: "0"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-addons
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    - type: remove
      path: /instance_groups/name=nats/azs?

    - type: remove
      path: /instance_groups/name=diego-api/azs?
    - type: remove
      path: /instance_groups/name=uaa/azs?
    - type: remove
      path: /instance_groups/name=singleton-blobstore/azs?
    - type: remove
      path: /instance_groups/name=api/azs?
    - type: remove
      path: /instance_groups/name=cc-worker/azs?
    - type: remove
      path: /instance_groups/name=scheduler/azs?
    - type: remove
      path: /instance_groups/name=router/azs?
    - type: remove
      path: /instance_groups/name=doppler/azs?
    - type: remove
      path: /instance_groups/name=log-api/azs?
    - type: remove
      path: /instance_groups/name=diego-cell/azs?
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-azs
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    # Remove all releases from cf-deployment; we'll only add back those we need
    - type: remove
      path: /releases
    - type: replace
      path: /releases?/name=binary-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=binary-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=binary-buildpack/version?
      value: "1.0.36"
    - type: replace
      path: /releases?/name=capi/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=capi/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=capi/version?
      value: "1.96.0"
    - type: replace
      path: /releases?/name=cf-cli/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=cf-cli/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=cf-cli/version?
      value: "1.27.0"
    - type: replace
      path: /releases?/name=cf-networking/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=cf-networking/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=cf-networking/version?
      value: "2.31.0"
    - type: replace
      path: /releases?/name=cf-smoke-tests/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=cf-smoke-tests/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=cf-smoke-tests/version?
      value: "40.0.134"
    - type: replace
      path: /releases?/name=cflinuxfs3/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=cflinuxfs3/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.2-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=cflinuxfs3/version?
      value: "0.203.0"
    - type: replace
      path: /releases?/name=diego/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=diego/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=diego/version?
      value: "2.47.0"
    - type: replace
      path: /releases?/name=dotnet-core-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=dotnet-core-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=dotnet-core-buildpack/version?
      value: "2.3.12"
    - type: replace
      path: /releases?/name=garden-runc/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=garden-runc/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=garden-runc/version?
      value: "1.19.14"
    - type: replace
      path: /releases?/name=go-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=go-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=go-buildpack/version?
      value: "1.9.14"
    - type: replace
      path: /releases?/name=java-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=java-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=java-buildpack/version?
      value: "4.32"
    - type: replace
      path: /releases?/name=log-cache/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=log-cache/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=log-cache/version?
      value: "2.7.2"
    - type: replace
      path: /releases?/name=loggregator/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=loggregator/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=loggregator/version?
      value: "106.3.10"
    - type: replace
      path: /releases?/name=loggregator-agent/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=loggregator-agent/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.2-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=loggregator-agent/version?
      value: "6.1.1"
    - type: replace
      path: /releases?/name=metrics-discovery/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=metrics-discovery/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=metrics-discovery/version?
      value: "3.0.1"
    - type: replace
      path: /releases?/name=nats/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=nats/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=nats/version?
      value: "34"
    - type: replace
      path: /releases?/name=nginx-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=nginx-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.2-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=nginx-buildpack/version?
      value: "1.1.11"
    - type: replace
      path: /releases?/name=nodejs-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=nodejs-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=nodejs-buildpack/version?
      value: "1.7.24"
    - type: replace
      path: /releases?/name=php-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=php-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=php-buildpack/version?
      value: "4.4.18"
    - type: replace
      path: /releases?/name=python-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=python-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=python-buildpack/version?
      value: "1.7.16"
    - type: replace
      path: /releases?/name=r-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=r-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.2-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=r-buildpack/version?
      value: "1.1.7"
    - type: replace
      path: /releases?/name=routing/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=routing/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=routing/version?
      value: "0.203.0"
    - type: replace
      path: /releases?/name=ruby-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=ruby-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=ruby-buildpack/version?
      value: "1.8.21"
    - type: replace
      path: /releases?/name=silk/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=silk/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.2-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=silk/version?
      value: "2.31.0"
    - type: replace
      path: /releases?/name=sle15/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=sle15/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=sle15/version?
      value: "10.93"
    - type: replace
      path: /releases?/name=staticfile-buildpack/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=staticfile-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=staticfile-buildpack/version?
      value: "1.5.9"
    - type: replace
      path: /releases?/name=statsd-injector/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=statsd-injector/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=statsd-injector/version?
      value: "1.11.15"
    - type: replace
      path: /releases?/name=suse-binary-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-binary-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-binary-buildpack/version?
      value: "1.0.36.1"
    - type: replace
      path: /releases?/name=suse-dotnet-core-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-dotnet-core-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-dotnet-core-buildpack/version?
      value: "2.3.9.1"
    - type: replace
      path: /releases?/name=suse-go-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-go-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-go-buildpack/version?
      value: "1.9.15.1"
    - type: replace
      path: /releases?/name=suse-java-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-java-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-java-buildpack/version?
      value: "4.32.1.1"
    - type: replace
      path: /releases?/name=suse-nginx-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-nginx-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-nginx-buildpack/version?
      value: "1.1.7.1"
    - type: replace
      path: /releases?/name=suse-nodejs-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-nodejs-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-nodejs-buildpack/version?
      value: "1.7.24.1"
    - type: replace
      path: /releases?/name=suse-php-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-php-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-php-buildpack/version?
      value: "4.4.18.1"
    - type: replace
      path: /releases?/name=suse-python-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-python-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-python-buildpack/version?
      value: "1.7.16.1"
    - type: replace
      path: /releases?/name=suse-ruby-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-ruby-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-ruby-buildpack/version?
      value: "1.8.21.1"
    - type: replace
      path: /releases?/name=suse-staticfile-buildpack/url
      value: registry.suse.com/cap-staging
    - type: replace
      path: /releases/name=suse-staticfile-buildpack/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=suse-staticfile-buildpack/version?
      value: "1.5.9.1"
    - type: replace
      path: /releases?/name=uaa/url
      value: docker.io/cfcontainerization
    - type: replace
      path: /releases/name=uaa/stemcell?
      value: {"os":"SLE_15_SP1","version":"27.1-7.0.0_374.gb8e8e6af"}
    - type: replace
      path: /releases/name=uaa/version?
      value: "74.23.0"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-releases
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    # We specify the new dependencies (I) and remove the old serialization
    # hints (II).
    #
    # I. Custom pod dependencies for startup sequencing
    #

    # Dependency graph (the first to run is at the left):
    #
    # api        --> cc-worker
    #            --> scheduler
    # nats       --> log-api
    #            --> singleton-blobstore       (feature: singleton-blobstore)
    # uaa        --> log-cache
    #            --> routing-api --> router    (feature: routing-api)
    #            --> tcp-router                (feature: routing-api)
    #            --> credhub                   (feature: credhub)
    #            --> diego-cell                (feature: not eirini)
    # deigo-api  --> auctioneer                (feature: not eirini)
    # asdatabase --> asactors                  (feature: autoscaler)
    #            --> asapi                     (feature: autoscaler)
    #            --> asmetrics   --> asnozzle  (feature: autoscaler)
    - type: replace
      path: /instance_groups/name=cc-worker/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"api\"]"
    - type: replace
      path: /instance_groups/name=scheduler/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"api\"]"
    - type: replace
      path: /instance_groups/name=log-api/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"nats\"]"
    - type: replace
      path: /instance_groups/name=log-cache/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"uaa\"]"
    - type: replace
      path: /instance_groups/name=auctioneer/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"diego-api\"]"
    - type: replace
      path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"uaa\"]"
    - type: replace
      path: /instance_groups/name=singleton-blobstore/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-for
      # ATTENTION: Annotations are strings. While the cf-operator's
      # controller will unmarshall the value as a json array later on,
      # specification must be done as a string using json syntax inside.
      value: "[\"nats\"]"

    #
    # II. Disable upstream pod startup serialization hints.
    #
    # Note: The serialization hints on the various test tasks are
    # irrelevant, and therefore ignored, and not changed.
    #
    - type: remove
      path: /instance_groups/name=router/update/serial
    - type: remove
      path: /instance_groups/name=auctioneer/update/serial
    - type: remove
      path: /instance_groups/name=singleton-blobstore/update/serial
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-sequencing
  namespace: default
---
apiVersion: v1
data:
  ops: |-
    - type: replace
      path: /name
      value: kubecf
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-set-deployment-name
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    - type: replace
      path: /instance_groups/name=api/instances
      value: 1
    - type: replace
      path: /instance_groups/name=api/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - api
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=cc-worker/instances
      value: 1
    - type: replace
      path: /instance_groups/name=cc-worker/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - cc-worker
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=diego-api/instances
      value: 1
    - type: replace
      path: /instance_groups/name=diego-api/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - diego-api
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=doppler/instances
      value: 1
    - type: replace
      path: /instance_groups/name=doppler/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - doppler
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=log-api/instances
      value: 1
    - type: replace
      path: /instance_groups/name=log-api/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - log-api
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=nats/instances
      value: 1
    - type: replace
      path: /instance_groups/name=nats/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - nats
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=router/instances
      value: 1
    - type: replace
      path: /instance_groups/name=router/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - router
              topologyKey: kubernetes.io/hostname
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - diego-cell
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=scheduler/instances
      value: 1
    - type: replace
      path: /instance_groups/name=scheduler/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - scheduler
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=uaa/instances
      value: 1
    - type: replace
      path: /instance_groups/name=uaa/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - uaa
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=auctioneer/instances
      value: 1
    - type: replace
      path: /instance_groups/name=auctioneer/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - auctioneer
              topologyKey: kubernetes.io/hostname
    - type: replace
      path: /instance_groups/name=diego-cell/instances
      value: 1
    - type: replace
      path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - diego-cell
              topologyKey: kubernetes.io/hostname
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: quarks.cloudfoundry.org/quarks-statefulset-name
                  operator: In
                  values:
                  - router
              topologyKey: kubernetes.io/hostname
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-sizing
  namespace: default
---
apiVersion: v1
data:
  ops: |2-

    - type: replace
      path: /instance_groups/name=api/jobs/name=binary-buildpack?/name
      value: "binary-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=binary-buildpack/release?
      value: "binary-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=binary-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=dotnet-core-buildpack?/name
      value: "dotnet-core-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=dotnet-core-buildpack/release?
      value: "dotnet-core-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=dotnet-core-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=go-buildpack?/name
      value: "go-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=go-buildpack/release?
      value: "go-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=go-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=java-buildpack?/name
      value: "java-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=java-buildpack/release?
      value: "java-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=java-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=nginx-buildpack?/name
      value: "nginx-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=nginx-buildpack/release?
      value: "nginx-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=nginx-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=nodejs-buildpack?/name
      value: "nodejs-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=nodejs-buildpack/release?
      value: "nodejs-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=nodejs-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=php-buildpack?/name
      value: "php-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=php-buildpack/release?
      value: "php-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=php-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=python-buildpack?/name
      value: "python-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=python-buildpack/release?
      value: "python-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=python-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=r-buildpack?/name
      value: "r-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=r-buildpack/release?
      value: "r-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=r-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=ruby-buildpack?/name
      value: "ruby-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=ruby-buildpack/release?
      value: "ruby-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=ruby-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=staticfile-buildpack?/name
      value: "staticfile-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=staticfile-buildpack/release?
      value: "staticfile-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=staticfile-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-binary-buildpack?/name
      value: "suse-binary-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-binary-buildpack/release?
      value: "suse-binary-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-binary-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-dotnet-core-buildpack?/name
      value: "suse-dotnet-core-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-dotnet-core-buildpack/release?
      value: "suse-dotnet-core-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-dotnet-core-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-go-buildpack?/name
      value: "suse-go-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-go-buildpack/release?
      value: "suse-go-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-go-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-java-buildpack?/name
      value: "suse-java-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-java-buildpack/release?
      value: "suse-java-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-java-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nginx-buildpack?/name
      value: "suse-nginx-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nginx-buildpack/release?
      value: "suse-nginx-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nginx-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nodejs-buildpack?/name
      value: "suse-nodejs-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nodejs-buildpack/release?
      value: "suse-nodejs-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nodejs-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-php-buildpack?/name
      value: "suse-php-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-php-buildpack/release?
      value: "suse-php-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-php-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-python-buildpack?/name
      value: "suse-python-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-python-buildpack/release?
      value: "suse-python-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-python-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-ruby-buildpack?/name
      value: "suse-ruby-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-ruby-buildpack/release?
      value: "suse-ruby-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-ruby-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-staticfile-buildpack?/name
      value: "suse-staticfile-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-staticfile-buildpack/release?
      value: "suse-staticfile-buildpack"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-staticfile-buildpack/properties?/quarks/bpm/processes
      value: []
    - type: replace
      path: /instance_groups/name=diego-cell/jobs/name=cflinuxfs3-rootfs-setup?
      value:
        name: cflinuxfs3-rootfs-setup
        release: cflinuxfs3
        properties:
          cflinuxfs3-rootfs:
            trusted_certs:
            - ((diego_instance_identity_ca.ca))
            - ((uaa_ssl.ca))
          quarks:
            bpm:
              processes: []
    - type: replace
      path: /instance_groups/name=diego-cell/jobs/name=sle15-rootfs-setup?
      value:
        name: sle15-rootfs-setup
        release: sle15
        properties:
          sle15-rootfs:
            trusted_certs:
            - ((diego_instance_identity_ca.ca))
            - ((uaa_ssl.ca))
          quarks:
            bpm:
              processes: []

    # set default stack
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/default_stack
      value: "sle15"
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/default_stack
      value: "sle15"
    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/default_stack
      value: "sle15"
    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/default_stack
      value: "sle15"

    # set stack list
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/stacks
      value: [{"description":"SUSE Linux Enterprise-based filesystem (SLE 15 SP1)","name":"sle15"},{"description":"Cloud Foundry Linux-based filesystem (Ubuntu 18.04)","name":"cflinuxfs3"}]
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/stacks
      value: [{"description":"SUSE Linux Enterprise-based filesystem (SLE 15 SP1)","name":"sle15"},{"description":"Cloud Foundry Linux-based filesystem (Ubuntu 18.04)","name":"cflinuxfs3"}]
    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/stacks
      value: [{"description":"SUSE Linux Enterprise-based filesystem (SLE 15 SP1)","name":"sle15"},{"description":"Cloud Foundry Linux-based filesystem (Ubuntu 18.04)","name":"cflinuxfs3"}]
    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/stacks
      value: [{"description":"SUSE Linux Enterprise-based filesystem (SLE 15 SP1)","name":"sle15"},{"description":"Cloud Foundry Linux-based filesystem (Ubuntu 18.04)","name":"cflinuxfs3"}]

    # set lifecycle bundles
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cc_deployment_updater?/properties/cc/diego/lifecycle_bundles
      value: {"buildpack/cflinuxfs3":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","buildpack/sle15":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","docker":"docker_app_lifecycle/docker_app_lifecycle.tgz"}
    - type: replace
      path: /instance_groups/name=scheduler/jobs/name=cloud_controller_clock?/properties/cc/diego/lifecycle_bundles
      value: {"buildpack/cflinuxfs3":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","buildpack/sle15":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","docker":"docker_app_lifecycle/docker_app_lifecycle.tgz"}
    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng?/properties/cc/diego/lifecycle_bundles
      value: {"buildpack/cflinuxfs3":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","buildpack/sle15":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","docker":"docker_app_lifecycle/docker_app_lifecycle.tgz"}
    - type: replace
      path: /instance_groups/name=cc-worker/jobs/name=cloud_controller_worker?/properties/cc/diego/lifecycle_bundles
      value: {"buildpack/cflinuxfs3":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","buildpack/sle15":"buildpack_app_lifecycle/buildpack_app_lifecycle.tgz","docker":"docker_app_lifecycle/docker_app_lifecycle.tgz"}
    # set list of pre-loaded rootfses
    - type: replace
      path: /instance_groups/name=diego-cell/jobs/name=rep/properties/diego/rep/preloaded_rootfses
      value:
      - sle15:/var/vcap/data/rep/sle15/rootfs.tar
      - cflinuxfs3:/var/vcap/data/rep/cflinuxfs3/rootfs.tar
    - type: replace
      path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/disks/-
      value:
        volumeMount:
          name: rep-data
          mountPath: /var/vcap/data/rep
        filters:
          job_name: "sle15-rootfs-setup"
          process_name: "sle15-rootfs-setup"
    - type: replace
      path: /instance_groups/name=diego-cell/env?/bosh/agent/settings/disks/-
      value:
        volumeMount:
          name: rep-data
          mountPath: /var/vcap/data/rep
        filters:
          job_name: "cflinuxfs3-rootfs-setup"
          process_name: "cflinuxfs3-rootfs-setup"

    # set list of all buildpacks in install order
    - type: replace
      path: /instance_groups/name=api/jobs/name=cloud_controller_ng/properties/cc/install_buildpacks
      value:
      - name: "staticfile_buildpack"
        file: "/var/vcap/data/shared-packages/suse-staticfile-buildpack/staticfile-buildpack-sle15-v1.5.9.1.zip"
      - name: "java_buildpack"
        file: "/var/vcap/data/shared-packages/suse-java-buildpack/java-buildpack-sle15-v4.32.1.1.zip"
      - name: "ruby_buildpack"
        file: "/var/vcap/data/shared-packages/suse-ruby-buildpack/ruby-buildpack-sle15-v1.8.21.1.zip"
      - name: "dotnet-core_buildpack"
        file: "/var/vcap/data/shared-packages/suse-dotnet-core-buildpack/dotnet-core-buildpack-sle15-v2.3.9.1.zip"
      - name: "nodejs_buildpack"
        file: "/var/vcap/data/shared-packages/suse-nodejs-buildpack/nodejs-buildpack-sle15-v1.7.24.1.zip"
      - name: "go_buildpack"
        file: "/var/vcap/data/shared-packages/suse-go-buildpack/go-buildpack-sle15-v1.9.15.1.zip"
      - name: "python_buildpack"
        file: "/var/vcap/data/shared-packages/suse-python-buildpack/python-buildpack-sle15-v1.7.16.1.zip"
      - name: "php_buildpack"
        file: "/var/vcap/data/shared-packages/suse-php-buildpack/php-buildpack-sle15-v4.4.18.1.zip"
      - name: "nginx_buildpack"
        file: "/var/vcap/data/shared-packages/suse-nginx-buildpack/nginx-buildpack-sle15-v1.1.7.1.zip"
      - name: "binary_buildpack"
        file: "/var/vcap/data/shared-packages/suse-binary-buildpack/binary-buildpack-sle15-v1.0.36.1.zip"
      - name: "binary_buildpack"
        file: "/var/vcap/data/shared-packages/binary-buildpack/binary-buildpack-cflinuxfs3-v1.0.36.zip"
      - name: "dotnet-core_buildpack"
        file: "/var/vcap/data/shared-packages/dotnet-core-buildpack/dotnet-core-buildpack-cflinuxfs3-v2.3.12.zip"
      - name: "go_buildpack"
        file: "/var/vcap/data/shared-packages/go-buildpack/go-buildpack-cflinuxfs3-v1.9.14.zip"
      - name: "java_buildpack"
        file: "/var/vcap/data/shared-packages/java-buildpack/java-buildpack-cflinuxfs3-v4.32.zip"
      - name: "nodejs_buildpack"
        file: "/var/vcap/data/shared-packages/nodejs-buildpack/nodejs-buildpack-cflinuxfs3-v1.7.24.zip"
      - name: "nginx_buildpack"
        file: "/var/vcap/data/shared-packages/nginx-buildpack/nginx-buildpack-cflinuxfs3-v1.1.11.zip"
      - name: "r_buildpack"
        file: "/var/vcap/data/shared-packages/r-buildpack/r-buildpack-cflinuxfs3-v1.1.7.zip"
      - name: "php_buildpack"
        file: "/var/vcap/data/shared-packages/php-buildpack/php-buildpack-cflinuxfs3-v4.4.18.zip"
      - name: "python_buildpack"
        file: "/var/vcap/data/shared-packages/python-buildpack/python-buildpack-cflinuxfs3-v1.7.16.zip"
      - name: "ruby_buildpack"
        file: "/var/vcap/data/shared-packages/ruby-buildpack/ruby-buildpack-cflinuxfs3-v1.8.21.zip"
      - name: "staticfile_buildpack"
        file: "/var/vcap/data/shared-packages/staticfile-buildpack/staticfile-buildpack-cflinuxfs3-v1.5.9.zip"

    # create pre-rendering scripts
    - type: replace
      path: /instance_groups/name=diego-cell/jobs/name=sle15-rootfs-setup/properties/quarks?/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        target="/var/vcap/all-releases/jobs-src/sle15/sle15-rootfs-setup/templates/pre-start"
        sentinel="${target}.patch_sentinel"
        if [[ -f "${sentinel}" ]]; then
          if sha256sum --check "${sentinel}" ; then
            echo "Patch already applied. Skipping"
            exit 0
          fi
          echo "Sentinel mismatch, re-patching"
        fi

        # Use the ephemeral data directory for the rootfs
        perl -p -i -e 's#\$ROOTFS_PACKAGE/rootfs#/var/vcap/data/rep/sle15/rootfs#' "${target}"

        sha256sum "${target}" > "${sentinel}"
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-staticfile-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-staticfile-buildpack"
        buildpack="suse-staticfile-buildpack"
        package="staticfile-buildpack-sle15"
        version="1.5.9.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-staticfile-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-staticfile-buildpack"
        job="suse-staticfile-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-java-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-java-buildpack"
        buildpack="suse-java-buildpack"
        package="java-buildpack-sle15"
        version="4.32.1.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-java-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-java-buildpack"
        job="suse-java-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-ruby-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-ruby-buildpack"
        buildpack="suse-ruby-buildpack"
        package="ruby-buildpack-sle15"
        version="1.8.21.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-ruby-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-ruby-buildpack"
        job="suse-ruby-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-dotnet-core-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-dotnet-core-buildpack"
        buildpack="suse-dotnet-core-buildpack"
        package="dotnet-core-buildpack-sle15"
        version="2.3.9.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-dotnet-core-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-dotnet-core-buildpack"
        job="suse-dotnet-core-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nodejs-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-nodejs-buildpack"
        buildpack="suse-nodejs-buildpack"
        package="nodejs-buildpack-sle15"
        version="1.7.24.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nodejs-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-nodejs-buildpack"
        job="suse-nodejs-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-go-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-go-buildpack"
        buildpack="suse-go-buildpack"
        package="go-buildpack-sle15"
        version="1.9.15.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-go-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-go-buildpack"
        job="suse-go-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-python-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-python-buildpack"
        buildpack="suse-python-buildpack"
        package="python-buildpack-sle15"
        version="1.7.16.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-python-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-python-buildpack"
        job="suse-python-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-php-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-php-buildpack"
        buildpack="suse-php-buildpack"
        package="php-buildpack-sle15"
        version="4.4.18.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-php-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-php-buildpack"
        job="suse-php-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nginx-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-nginx-buildpack"
        buildpack="suse-nginx-buildpack"
        package="nginx-buildpack-sle15"
        version="1.1.7.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-nginx-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-nginx-buildpack"
        job="suse-nginx-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-binary-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="suse-binary-buildpack"
        buildpack="suse-binary-buildpack"
        package="binary-buildpack-sle15"
        version="1.0.36.1"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=suse-binary-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="suse-binary-buildpack"
        job="suse-binary-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=diego-cell/jobs/name=cflinuxfs3-rootfs-setup/properties/quarks?/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        target="/var/vcap/all-releases/jobs-src/cflinuxfs3/cflinuxfs3-rootfs-setup/templates/pre-start"
        sentinel="${target}.patch_sentinel"
        if [[ -f "${sentinel}" ]]; then
          if sha256sum --check "${sentinel}" ; then
            echo "Patch already applied. Skipping"
            exit 0
          fi
          echo "Sentinel mismatch, re-patching"
        fi

        # Use the ephemeral data directory for the rootfs
        perl -p -i -e 's#\$ROOTFS_PACKAGE/rootfs#/var/vcap/data/rep/cflinuxfs3/rootfs#' "${target}"

        sha256sum "${target}" > "${sentinel}"
    - type: replace
      path: /instance_groups/name=api/jobs/name=binary-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="binary-buildpack"
        buildpack="binary-buildpack"
        package="binary-buildpack-cflinuxfs3"
        version="1.0.36"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=binary-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="binary-buildpack"
        job="binary-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=dotnet-core-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="dotnet-core-buildpack"
        buildpack="dotnet-core-buildpack"
        package="dotnet-core-buildpack-cflinuxfs3"
        version="2.3.12"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=dotnet-core-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="dotnet-core-buildpack"
        job="dotnet-core-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=go-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="go-buildpack"
        buildpack="go-buildpack"
        package="go-buildpack-cflinuxfs3"
        version="1.9.14"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=go-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="go-buildpack"
        job="go-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=java-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="java-buildpack"
        buildpack="java-buildpack"
        package="java-buildpack-cflinuxfs3"
        version="4.32"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=java-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="java-buildpack"
        job="java-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=nodejs-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="nodejs-buildpack"
        buildpack="nodejs-buildpack"
        package="nodejs-buildpack-cflinuxfs3"
        version="1.7.24"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=nodejs-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="nodejs-buildpack"
        job="nodejs-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=nginx-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="nginx-buildpack"
        buildpack="nginx-buildpack"
        package="nginx-buildpack-cflinuxfs3"
        version="1.1.11"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=nginx-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="nginx-buildpack"
        job="nginx-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=r-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="r-buildpack"
        buildpack="r-buildpack"
        package="r-buildpack-cflinuxfs3"
        version="1.1.7"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=r-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="r-buildpack"
        job="r-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=php-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="php-buildpack"
        buildpack="php-buildpack"
        package="php-buildpack-cflinuxfs3"
        version="4.4.18"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=php-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="php-buildpack"
        job="php-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=python-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="python-buildpack"
        buildpack="python-buildpack"
        package="python-buildpack-cflinuxfs3"
        version="1.7.16"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=python-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="python-buildpack"
        job="python-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=ruby-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="ruby-buildpack"
        buildpack="ruby-buildpack"
        package="ruby-buildpack-cflinuxfs3"
        version="1.8.21"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=ruby-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="ruby-buildpack"
        job="ruby-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=staticfile-buildpack/properties?/quarks/pre_render_scripts/jobs/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Create the pre-start script that copies the buildpack package to /var/vcap/data/shared-packages/.

        release="staticfile-buildpack"
        buildpack="staticfile-buildpack"
        package="staticfile-buildpack-cflinuxfs3"
        version="1.5.9"

        pre_start="/var/vcap/all-releases/jobs-src/${release}/${buildpack}/templates/bin/pre-start"
        copy_dst="/var/vcap/data/shared-packages/${buildpack}"
        mkdir -p "$(dirname "${pre_start}")"
        cat <<EOT > "${pre_start}"
        #!/usr/bin/env bash
        set -o errexit
        mkdir -p "${copy_dst}"
        cp /var/vcap/packages/${package}/*.zip "${copy_dst}/${package}-v${version}.zip"
        EOT
    - type: replace
      path: /instance_groups/name=api/jobs/name=staticfile-buildpack/properties?/quarks/pre_render_scripts/ig_resolver/-
      value: |
        #!/usr/bin/env bash
        set -o errexit -o nounset

        # Add bin/pre-start to the buildpack job templates.

        release="staticfile-buildpack"
        job="staticfile-buildpack"

        job_mf="/var/vcap/all-releases/jobs-src/${release}/${job}/job.MF"

        sed -i 's|templates: {}||' "${job_mf}"
        cat <<EOT > "${job_mf}"
        templates:
          bin/pre-start: bin/pre-start
        EOT
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-stacks
  namespace: default
---
apiVersion: v1
data:
  ops: |2-


    - type: replace
      path: /stemcells/alias=default
      value:
        alias: default
        os: "SLE_15_SP1"
        version: "27.1-7.0.0_374.gb8e8e6af"
    - type: replace
      path: /addons/name=forwarder_agent/include/stemcell/os=ubuntu-xenial/os
      value: "SLE_15_SP1"
    - type: replace
      path: /addons/name=loggr-syslog-agent/include/stemcell/os=ubuntu-xenial/os
      value: "SLE_15_SP1"
    - type: replace
      path: /addons/name=loggregator_agent/include/stemcell/os=ubuntu-xenial/os
      value: "SLE_15_SP1"
    - type: replace
      path: /addons/name=prom_scraper/include/stemcell/os=ubuntu-xenial/os
      value: "SLE_15_SP1"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: ops-stemcells
  namespace: default
---
apiVersion: v1
data:
  ops: ""
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: operations
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: user-provided-properties
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: kubecf-default-psp
  namespace: default
rules:
- apiGroups:
  - policy
  resourceNames:
  - kubecf-default
  resources:
  - podsecuritypolicies
  verbs:
  - use
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  name: kubecf-default-psp
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubecf-default-psp
subjects:
- kind: ServiceAccount
  name: default
  namespace: default
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: database
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database
  namespace: default
spec:
  ports:
  - name: mysql
    port: 3306
    targetPort: mysql
  selector:
    app: database
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    quarks.cloudfoundry.org/pod-active: active
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: database
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database-repl
  namespace: default
spec:
  clusterIP: None
  ports:
  - name: galera
    port: 4567
  - name: state-xfer
    port: 4568
  - name: state-snap
    port: 4444
  selector:
    app: database
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/backend-protocol: HTTPS
    nginx.ingress.kubernetes.io/proxy-body-size: 64m
    nginx.ingress.kubernetes.io/secure-backends: "true"
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.org/websocket-services: router
  labels:
    app.kubernetes.io/component: ingress
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: kubecf
  namespace: default
spec:
  rules:
  - host: '*.kubecf.vcap.me'
    http:
      paths:
      - backend:
          serviceName: router
          servicePort: 443
        path: /
  tls:
  - hosts:
    - '*.kubecf.vcap.me'
    secretName: kubecf-ingress-tls
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: BOSHDeployment
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: kubecf
  namespace: default
spec:
  manifest:
    name: cf-deployment
    type: configmap
  ops:
  - name: ops-move-auctioneer
    type: configmap
  - name: ops-move-log-cache
    type: configmap
  - name: ops-move-routing-api
    type: configmap
  - name: ops-acceptance-tests
    type: configmap
  - name: ops-api
    type: configmap
  - name: ops-app-autoscaler
    type: configmap
  - name: ops-auctioneer
    type: configmap
  - name: ops-brain-tests
    type: configmap
  - name: ops-cc-worker
    type: configmap
  - name: ops-credhub
    type: configmap
  - name: ops-database
    type: configmap
  - name: ops-diego-api
    type: configmap
  - name: ops-diego-cell
    type: configmap
  - name: ops-doppler
    type: configmap
  - name: ops-eirini-helm
    type: configmap
  - name: ops-log-api
    type: configmap
  - name: ops-log-cache
    type: configmap
  - name: ops-nats
    type: configmap
  - name: ops-router
    type: configmap
  - name: ops-routing-api
    type: configmap
  - name: ops-scheduler
    type: configmap
  - name: ops-singleton-blobstore
    type: configmap
  - name: ops-smoke-tests
    type: configmap
  - name: ops-sync-integration-tests
    type: configmap
  - name: ops-tcp-router
    type: configmap
  - name: ops-uaa
    type: configmap
  - name: ops-sizing
    type: configmap
  - name: ops-azs
    type: configmap
  - name: ops-addons
    type: configmap
  - name: ops-azs
    type: configmap
  - name: ops-releases
    type: configmap
  - name: ops-sequencing
    type: configmap
  - name: ops-set-deployment-name
    type: configmap
  - name: ops-sizing
    type: configmap
  - name: ops-stacks
    type: configmap
  - name: ops-stemcells
    type: configmap
  - name: user-provided-properties
    type: configmap
  vars: []
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksJob
metadata:
  annotations:
    kbld.k14s.io/images: |
      - Metas:
        - Tag: 0.9.11
          Type: resolved
          URL: docker.io/cfcontainerization/pxc:0.9.11
        URL: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database-seeder
  namespace: default
spec:
  template:
    spec:
      template:
        spec:
          containers:
          - command:
            - /bin/bash
            - -c
            - |-
              #!/usr/bin/env bash

              set -o errexit -o nounset -o pipefail

              cat > "${HOME}/.my.cnf" <<EOF
              [mysql]
              host=${DATABASE_HOST}
              user=root
              password=${DATABASE_ROOT_PASSWORD}
              EOF

              echo "Waiting for database to be ready..."
              until echo "SELECT 'Ready!'" | mysql --connect-timeout=3 1> /dev/null 2> /dev/null; do
                sleep 1
              done

              mysql < <(
                echo "START TRANSACTION;"
                echo "\
                  CREATE DATABASE IF NOT EXISTS kubecf
                    DEFAULT CHARACTER SET ${CHARACTER_SET}
                    DEFAULT COLLATE ${COLLATE};
                  USE kubecf;
                  CREATE TABLE IF NOT EXISTS db_leader_election (
                    anchor tinyint(3) unsigned NOT NULL,
                    host varchar(128) NOT NULL,
                    last_seen_active timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (anchor)
                  );"
                for database in ${DATABASES}; do
                  if [[ -z "${database}" ]]; then continue; fi

                  password=$(</passwords/"${database}"/password)

                  echo "\
                    CREATE USER IF NOT EXISTS \`${database}\`;
                    ALTER USER \`${database}\` IDENTIFIED BY '${password}';

                    CREATE DATABASE IF NOT EXISTS \`${database}\`
                      DEFAULT CHARACTER SET ${CHARACTER_SET}
                      DEFAULT COLLATE ${COLLATE};

                    GRANT ALL ON \`${database}\`.* TO '${database}'@'%';
                  "
                done
                echo "COMMIT;"
              )
              echo "Done!"
            env:
            - name: DATABASE_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: var-pxc-root-password
            - name: DATABASE_HOST
              value: database.default
            - name: CHARACTER_SET
              value: utf8
            - name: COLLATE
              value: utf8_unicode_ci
            - name: DATABASES
              value: |-
                cloud_controller
                diego
                network_connectivity
                network_policy
                uaa
                locket
            image: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
            imagePullPolicy: null
            name: seeder
            volumeMounts:
            - mountPath: /passwords/cloud_controller
              name: cloud-controller-database-password
              readOnly: true
            - mountPath: /passwords/diego
              name: diego-database-password
              readOnly: true
            - mountPath: /passwords/network_connectivity
              name: network-connectivity-database-password
              readOnly: true
            - mountPath: /passwords/network_policy
              name: network-policy-database-password
              readOnly: true
            - mountPath: /passwords/uaa
              name: uaa-database-password
              readOnly: true
            - mountPath: /passwords/locket
              name: locket-database-password
              readOnly: true
          restartPolicy: Never
          volumes:
          - name: cloud-controller-database-password
            secret:
              secretName: var-cc-database-password
          - name: diego-database-password
            secret:
              secretName: var-diego-database-password
          - name: network-connectivity-database-password
            secret:
              secretName: var-network-connectivity-database-password
          - name: network-policy-database-password
            secret:
              secretName: var-network-policy-database-password
          - name: uaa-database-password
            secret:
              secretName: var-uaa-database-password
          - name: locket-database-password
            secret:
              secretName: var-locket-database-password
  trigger:
    strategy: once
  updateOnConfigChange: true
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksJob
metadata:
  annotations:
    kbld.k14s.io/images: |
      - Metas:
        - Tag: 0.9.11
          Type: resolved
          URL: docker.io/cfcontainerization/pxc:0.9.11
        URL: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database-migrate-charset
  namespace: default
spec:
  template:
    spec:
      template:
        spec:
          containers:
          - command:
            - /bin/bash
            - -c
            - |-
              #!/usr/bin/env bash

              # This script migrates the character set and collate of the KubeCF databases. This was originally
              # introduced to migrate from latin1 to utf8 on existing installations up to v2.1.0.

              set -o errexit -o nounset -o pipefail

              cat > "${HOME}/.my.cnf" <<EOF
              [mysql]
              host=${DATABASE_HOST}
              user=root
              password=${DATABASE_ROOT_PASSWORD}
              EOF

              echo "Waiting for database to be ready..."
              until echo "SELECT 'Ready!'" | mysql --connect-timeout=3 1> /dev/null 2> /dev/null; do
                sleep 1
              done

              function show_tables() {
                local database=$1
                mysql \
                  --database="${database}" \
                  --batch \
                  --skip-column-names \
                  --execute "SHOW TABLES"
              }

              function show_columns() {
                local database=$1
                local table=$2
                mysql \
                  --database="${database}" \
                  --batch \
                  --skip-column-names \
                  --execute "SHOW COLUMNS FROM ${table}"
              }

              function alter_tables() {
                local database=$1

                while read -r table; do
                  >&2 echo "Generating statements for \`${database}\`.\`${table}\`..."

                  echo "ALTER TABLE \`${table}\` DEFAULT CHARACTER SET ${CHARACTER_SET};"

                  while read -r column; do
                    field_type=$(awk --field-separator="\t" '{ print toupper($2) }' <<<"${column}")

                    awk_program='/^(CHAR|VARCHAR|TINYTEXT|TEXT|MEDIUMTEXT|LONGTEXT|ENUM|SET)/ { print "modify" }'
                    if [[ "$(awk "${awk_program}" <<<"${field_type}")" == "modify" ]]; then
                      field_name=$(awk --field-separator="\t" '{ print $1 }' <<<"${column}")
                      null_opt=$(awk --field-separator="\t" '{ print ($3 == "YES") ? "NULL" : "NOT NULL"}' <<<"${column}")
                      field_default=$(awk --field-separator="\t" '{ print $5 }' <<<"${column}")
                      if [[ "${field_default}" == "NULL" ]]; then
                        if [[ "${null_opt}" == "NOT NULL" ]]; then
                          default_opt=""
                        else
                          default_opt="DEFAULT NULL"
                        fi
                      else
                        default_opt="DEFAULT '${field_default}'"
                      fi

                      echo "ALTER TABLE \`${table}\` MODIFY \`${field_name}\` ${field_type} CHARACTER SET ${CHARACTER_SET} ${null_opt} ${default_opt};"
                    fi
                  done < <(show_columns "${database}" "${table}")
                done < <(show_tables "${database}")
              }

              function get_charset() {
                local database=$1
                mysql \
                  --database="${database}" \
                  --batch \
                  --skip-column-names \
                  --execute "SELECT default_character_set_name FROM information_schema.SCHEMATA WHERE schema_name = '${database}';"
              }

              function alter_database() {
                local database=$1

                current_charset=$(get_charset "${database}")
                if [[ "${current_charset}" == "${CHARACTER_SET}" ]]; then
                  return 0
                fi

                echo "ALTER DATABASE \`${database}\` DEFAULT CHARACTER SET ${CHARACTER_SET} DEFAULT COLLATE ${COLLATE};"
                echo "USE \`${database}\`;"
                echo "SET sql_mode = 'NO_AUTO_VALUE_ON_ZERO';"
                echo "SET foreign_key_checks = 0;"

                alter_tables "${database}"

                echo "SET foreign_key_checks = 1;"
                echo -e "\n"
              }

              STATEMENT=$(
              echo "START TRANSACTION;"

              alter_database "kubecf"

              for database in ${DATABASES}; do
                if [[ -z "${database}" ]]; then continue; fi
                alter_database "${database}"
              done

              echo "COMMIT;"
              )

              mysql <<<"${STATEMENT}"
            env:
            - name: DATABASE_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: var-pxc-root-password
            - name: DATABASE_HOST
              value: database.default
            - name: CHARACTER_SET
              value: utf8
            - name: COLLATE
              value: utf8_unicode_ci
            - name: DATABASES
              value: |-
                cloud_controller
                diego
                network_connectivity
                network_policy
                uaa
                locket
            image: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
            imagePullPolicy: null
            name: migrate-charset
            volumeMounts:
            - mountPath: /passwords/cloud_controller
              name: cloud-controller-database-password
              readOnly: true
            - mountPath: /passwords/diego
              name: diego-database-password
              readOnly: true
            - mountPath: /passwords/network_connectivity
              name: network-connectivity-database-password
              readOnly: true
            - mountPath: /passwords/network_policy
              name: network-policy-database-password
              readOnly: true
            - mountPath: /passwords/uaa
              name: uaa-database-password
              readOnly: true
            - mountPath: /passwords/locket
              name: locket-database-password
              readOnly: true
          restartPolicy: Never
          volumes:
          - name: cloud-controller-database-password
            secret:
              secretName: var-cc-database-password
          - name: diego-database-password
            secret:
              secretName: var-diego-database-password
          - name: network-connectivity-database-password
            secret:
              secretName: var-network-connectivity-database-password
          - name: network-policy-database-password
            secret:
              secretName: var-network-policy-database-password
          - name: uaa-database-password
            secret:
              secretName: var-uaa-database-password
          - name: locket-database-password
            secret:
              secretName: var-locket-database-password
  trigger:
    strategy: manual
  updateOnConfigChange: true
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksSecret
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: var-pxc-root-password
  namespace: default
spec:
  secretName: var-pxc-root-password
  type: password
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksSecret
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: var-pxc-password
  namespace: default
spec:
  secretName: var-pxc-password
  type: password
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksSecret
metadata:
  labels:
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: var-xtrabackup-password
  namespace: default
spec:
  secretName: var-xtrabackup-password
  type: password
---
apiVersion: quarks.cloudfoundry.org/v1alpha1
kind: QuarksStatefulSet
metadata:
  annotations:
    kbld.k14s.io/images: |
      - Metas:
        - Tag: 0.9.11
          Type: resolved
          URL: docker.io/cfcontainerization/pxc:0.9.11
        URL: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
      - Metas:
        - Tag: 0.9.11
          Type: resolved
          URL: docker.io/cfcontainerization/pxc:0.9.11
        URL: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
      - Metas:
        - Tag: 0.9.11
          Type: resolved
          URL: docker.io/cfcontainerization/pxc:0.9.11
        URL: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
  labels:
    app: database
    app.kubernetes.io/instance: kubecf
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kubecf
    app.kubernetes.io/version: 2.4.0
    helm.sh/chart: kubecf-2.4.0
  name: database
  namespace: default
spec:
  activePassiveProbes:
    database:
      exec:
        command:
        - /bin/bash
        - -c
        - |
          #!/usr/bin/env bash

          leader=$(mysql -sN <<EOF
            USE kubecf;
            insert ignore into db_leader_election ( anchor, host, last_seen_active )
              values ( 1, '${HOSTNAME}', now() ) on duplicate key update host = if(last_seen_active < now() - interval 20 second,
              values(host), host), last_seen_active = if(host = values(host), values(last_seen_active), last_seen_active);
              select host from db_leader_election;
          EOF
          )

          # shellcheck disable=SC2181
          if [[ $? != 0 ]]; then
            # the kubecf database doesn't seem to be ready. make the first node the master
            [[ ${HOSTNAME} == *-0 ]] || exit 2
          else
            [[ "${leader}" == "${HOSTNAME}" ]]
          fi
      periodSeconds: 5
  template:
    metadata:
      labels:
        app: database
        app.kubernetes.io/instance: kubecf
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kubecf
        app.kubernetes.io/version: 2.4.0
        helm.sh/chart: kubecf-2.4.0
      name: database
      namespace: default
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: database
          app.kubernetes.io/instance: kubecf
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kubecf
          app.kubernetes.io/version: 2.4.0
          helm.sh/chart: kubecf-2.4.0
      serviceName: database
      template:
        metadata:
          labels:
            app: database
            app.kubernetes.io/instance: kubecf
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: kubecf
            app.kubernetes.io/version: 2.4.0
            helm.sh/chart: kubecf-2.4.0
        spec:
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: quarks.cloudfoundry.org/quarks-statefulset-name
                      operator: In
                      values:
                      - database
                  topologyKey: kubernetes.io/hostname
                weight: 100
          containers:
          - command:
            - /bin/bash
            - /startup-scripts/entrypoint.sh
            env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: var-pxc-root-password
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: var-pxc-password
            - name: XTRABACKUP_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: var-xtrabackup-password
            - name: ALLOW_ROOT_FROM
              value: '%'
            - name: CLUSTER_NAME
              value: kubecf-database
            - name: SHORT_CLUSTER_NAME
              value: kubecf-database
            - name: K8S_SERVICE_NAME
              value: database-repl
            - name: PXC_STRICT_MODE
              value: ENFORCING
            image: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
            imagePullPolicy: null
            livenessProbe:
              exec:
                command:
                - /bin/bash
                - -c
                - mysqladmin ping || test -e /var/lib/mysql/sst_in_progress
              initialDelaySeconds: 30
              timeoutSeconds: 2
            name: database
            ports:
            - containerPort: 3306
              name: mysql
            - containerPort: 4567
              name: galera-repl
            - containerPort: 4568
              name: state-transfer
            - containerPort: 4444
              name: state-snapshot
            readinessProbe:
              exec:
                command:
                - mysql
                - -h
                - 127.0.0.1
                - -e
                - SELECT 1
              initialDelaySeconds: 30
              timeoutSeconds: 2
            volumeMounts:
            - mountPath: /etc/mysql/tls/certs
              name: pxc-tls
            - mountPath: /var/lib/mysql
              name: pxc-data
            - mountPath: /etc/mysql/conf.d
              name: pxc-config-files
            - mountPath: /startup-scripts
              name: pxc-startup-scripts
            - mountPath: /root
              name: slash-root
            - mountPath: /var/log
              name: var-log
          - command:
            - tail
            - -f
            - /var/log/mysqld.log
            image: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
            imagePullPolicy: null
            name: logs
            volumeMounts:
            - mountPath: /var/log
              name: var-log
          initContainers:
          - command:
            - rm
            - -fr
            - /var/lib/mysql/lost+found
            image: index.docker.io/cfcontainerization/pxc@sha256:c3a0d231824d2d2920696411d17626d473d408be299a7ca13bbb1f614887b05d
            imagePullPolicy: null
            name: remove-lost-found
            volumeMounts:
            - mountPath: /var/lib/mysql
              name: pxc-data
          volumes:
          - emptyDir: {}
            name: slash-root
          - emptyDir: {}
            name: var-log
          - configMap:
              name: database-config-files
            name: pxc-config-files
          - configMap:
              name: database-startup-scripts
            name: pxc-startup-scripts
          - name: pxc-tls
            secret:
              secretName: var-pxc-tls
      volumeClaimTemplates:
      - metadata:
          name: pxc-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 20Gi
          storageClassName: null
  updateOnConfigChange: true
